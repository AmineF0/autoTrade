{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout,SimpleRNN,BatchNormalization,GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class StockPredictor:\n",
    "    def __init__(self,stock_name='AAPL',interval=\"1h\",period=\"2y\",split_ratio=1,window_size=6):\n",
    "        self.stock_name = stock_name\n",
    "        self.split_ratio = split_ratio\n",
    "        self.period = period\n",
    "        self.interval = interval\n",
    "        self.window_size = window_size\n",
    "        self.data = yf.download(self.stock_name, period=self.period,interval=self.interval)\n",
    "        self.data = self.data.dropna()\n",
    "        self.data.columns = self.data.columns.droplevel(1) \n",
    "    \n",
    "    def get_stock_data(self):\n",
    "        stock_data = yf.download(self.stock_name, period=self.period,interval=self.interval)\n",
    "        stock_data = stock_data.dropna()\n",
    "        cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        stock_data.columns = cols\n",
    "        return stock_data\n",
    "    \n",
    "    def window_data_univariate(self,data, window_size):\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for i in range(len(data) - window_size - 1):\n",
    "            X.append(data[i:(i + window_size)])\n",
    "            y.append(data[i + window_size])\n",
    "        return np.array(X), np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    def window_data_multivariate(self,data,close_data, window_size):\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for i in range(len(data) - window_size - 1):\n",
    "            # Window includes all features\n",
    "            X.append(data[i:(i + window_size), :])\n",
    "            # Target is next day's closing price\n",
    "            y.append(close_data[i + window_size])  # Closing price is first column\n",
    "            \n",
    "        return np.array(X), np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    def build_lstm_model(self,X_train):\n",
    "        model = Sequential([\n",
    "            LSTM(units=128, \n",
    "            return_sequences=True, \n",
    "            input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        LSTM(units=64),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "        ])\n",
    "        optimizer = Adam(learning_rate=0.01)\n",
    "        model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "        return model\n",
    "    \n",
    "    def build_mlp_model(self):\n",
    "        model_mlp = MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=100, verbose=False)\n",
    "        return model_mlp\n",
    "    \n",
    "    def get_current_price(self):\n",
    "        stock_data = yf.download(self.stock_name, period='2y',interval='1h')\n",
    "        return stock_data['Close'].to_numpy()[-1]\n",
    "    \n",
    "    def train_lstm_univariate(self):\n",
    "        scaler = MinMaxScaler()\n",
    "        data_close = self.data['Close']\n",
    "        df_windowed,df_target = self.window_data_univariate(data_close.to_numpy().reshape(-1,1),self.window_size)\n",
    "        df_windowed_reshaped = df_windowed.reshape(df_windowed.shape[0], -1)\n",
    "        x_scaler = scaler.fit(df_windowed_reshaped)\n",
    "        df_windowed_reshaped = x_scaler.transform(df_windowed_reshaped)\n",
    "        df_windowed = df_windowed_reshaped.reshape(df_windowed.shape[0], df_windowed.shape[1], df_windowed.shape[2])\n",
    "        y_scaler = scaler.fit(df_target)\n",
    "        df_target = y_scaler.transform(df_target)\n",
    "        train_size = int(self.split_ratio*len(df_windowed))\n",
    "        X_train = df_windowed[:train_size]\n",
    "        y_train = df_target[:train_size]\n",
    "        X_test = df_windowed[train_size:]\n",
    "        y_test = df_target[train_size:]\n",
    "        model = self.build_lstm_model(X_train)\n",
    "        model.fit(X_train, y_train, epochs=100,batch_size=32,    \n",
    "            validation_split=0.1,\n",
    "            verbose=0)\n",
    "\n",
    "        model.save(f'models/{self.stock_name}/LSTM_univariate_{self.period}_{self.interval}.h5')\n",
    "     \n",
    "    def train_lstm_multivariante(self):\n",
    "        scaler = MinMaxScaler()\n",
    "        data = self.data[['Close', 'High', 'Low', 'Volume']]\n",
    "        data_close = self.data['Close']\n",
    "        df_windowed,df_target = self.window_data_multivariate(data.to_numpy(),data_close.to_numpy().reshape(-1,1),self.window_size)\n",
    "        df_windowed_reshaped = df_windowed.reshape(df_windowed.shape[0], -1)\n",
    "        x_scaler = scaler.fit(df_windowed_reshaped)\n",
    "        df_windowed_reshaped = x_scaler.transform(df_windowed_reshaped)\n",
    "        df_windowed = df_windowed_reshaped.reshape(df_windowed.shape[0], df_windowed.shape[1], df_windowed.shape[2])\n",
    "        y_scaler = scaler.fit(df_target)\n",
    "        df_target = y_scaler.transform(df_target)\n",
    "        train_size = int(self.split_ratio*len(df_windowed))\n",
    "        X_train = df_windowed[:train_size]\n",
    "        y_train = df_target[:train_size]\n",
    "        X_test = df_windowed[train_size:]\n",
    "        y_test = df_target[train_size:]\n",
    "        model = self.build_lstm_model(X_train)\n",
    "        model.fit(X_train, y_train, epochs=100,batch_size=32,    \n",
    "            validation_split=0.1,\n",
    "            verbose=0)\n",
    "\n",
    "        model.save(f'models/{self.stock_name}/LSTM_multivariate_{self.period}_{self.interval}.h5')   \n",
    "        \n",
    "    def train_mlp_univariante(self):\n",
    "        scaler = MinMaxScaler()\n",
    "        data_close = self.data['Close']\n",
    "        df_windowed,df_target = self.window_data_univariate(data_close.to_numpy().reshape(-1,1),self.window_size)\n",
    "        df_windowed_reshaped = df_windowed.reshape(df_windowed.shape[0], -1)\n",
    "        x_scaler = scaler.fit(df_windowed_reshaped)\n",
    "        df_windowed_reshaped = x_scaler.transform(df_windowed_reshaped)\n",
    "        df_windowed = df_windowed_reshaped.reshape(df_windowed.shape[0], df_windowed.shape[1], df_windowed.shape[2])\n",
    "        y_scaler = scaler.fit(df_target)\n",
    "        df_target = y_scaler.transform(df_target)\n",
    "        train_size = int(self.split_ratio*len(df_windowed))\n",
    "        X_train = df_windowed[:train_size]\n",
    "        y_train = df_target[:train_size]\n",
    "        X_test = df_windowed[train_size:]\n",
    "        y_test = df_target[train_size:]\n",
    "        model = self.build_mlp_model()\n",
    "        model.fit(X_train.reshape(X_train.shape[0],-1), y_train)\n",
    "        output_dir = f'models/{self.stock_name}'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        with open(f'models/{self.stock_name}/MLP_univaraite_{self.period}_{self.interval}.pkl', 'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "    \n",
    "    def model_expiry(self):\n",
    "        EXPIRY_CST = 2*60*60\n",
    "        models = [f\"MLP_univaraite__{self.period}_{self.interval}\",f\"LSTM_univariate_{self.period}_{self.interval}\",f\"LSTM_multivariate_{self.period}_{self.interval}\"]\n",
    "        # check if json file with name models_manager exist in models folder \n",
    "        if not os.path.exists(f'models/{self.stock_name}/models_manager.json'):\n",
    "            return True\n",
    "        with open(f'models/{self.stock_name}/models_manager.json', 'r') as file:\n",
    "            data = json.load(file)\n",
    "            for model in models:\n",
    "                if model not in data:\n",
    "                    return True\n",
    "                else:\n",
    "                    creation_date = data[model]['creation_date']\n",
    "                    creation_date = dt.datetime.fromtimestamp(creation_date)\n",
    "                    now = dt.datetime.now()\n",
    "                    diff = (now - creation_date).total_seconds()\n",
    "                    return diff > EXPIRY_CST\n",
    "                \n",
    "    \n",
    "    def train(self, force: bool = False):\n",
    "        \n",
    "        # TODO : detect the expiry of the model using the json file, json create name path of the model\n",
    "        # diff( now - created ) > cst train else skip\n",
    "        # if force is True, train the model\n",
    "        if force or self.model_expiry():\n",
    "            self.train_lstm_univariate()\n",
    "            self.train_lstm_multivariante()\n",
    "            self.train_mlp_univariante()\n",
    "            data = {\n",
    "                    f\"MLP_univaraite_{self.period}_{self.interval}\":{\n",
    "                        'path':f'models/{self.stock_name}/MLP_univaraite_{self.period}_{self.interval}.pkl',\n",
    "                        \"creation_date\":dt.datetime.now().timestamp()\n",
    "                    },\n",
    "                    f\"LSTM_univariate_{self.period}_{self.interval}.h5\":{\n",
    "                        'path':f'models/{self.stock_name}/LSTM_univariate_{self.period}_{self.interval}.h5',\n",
    "                        \"creation_date\":dt.datetime.now().timestamp()\n",
    "                    },\n",
    "                    f\"LSTM_multivariate_{self.period}_{self.interval}\":{\n",
    "                        'path':f'models/{self.stock_name}/LSTM_multivariate_{self.period}_{self.interval}.h5',\n",
    "                        \"creation_date\":dt.datetime.now().timestamp()\n",
    "                    }\n",
    "                }\n",
    "            with open(f'models/{self.stock_name}/models_manager.json', 'w') as file:\n",
    "                json.dump(data, file)\n",
    "            \n",
    "    \n",
    "    def forecast_lstm_univariante(self,n_instances:int=7):\n",
    "        model_dir = f'models/{self.stock_name}/LSTM_univariate_{self.period}_{self.interval}.h5'\n",
    "        model = tf.keras.models.load_model(model_dir)\n",
    "        forecast = []\n",
    "        data_close = self.data['Close']\n",
    "        df_windowed,df_target = self.window_data_univariate(data_close.to_numpy().reshape(-1,1),self.window_size)\n",
    "        df_windowed_reshaped = df_windowed.reshape(df_windowed.shape[0], -1)\n",
    "        x_scaler = MinMaxScaler()\n",
    "        x_scaler.fit(df_windowed_reshaped)\n",
    "        df_windowed_reshaped = x_scaler.transform(df_windowed_reshaped)\n",
    "        df_windowed = df_windowed_reshaped.reshape(df_windowed.shape[0], df_windowed.shape[1], df_windowed.shape[2])\n",
    "        y_scaler = MinMaxScaler()\n",
    "        y_scaler.fit(df_target)\n",
    "        df_target = y_scaler.transform(df_target)\n",
    "        X = df_windowed[-1]\n",
    "        for i in range(n_instances):\n",
    "            X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "            y_pred = model.predict(X)\n",
    "            forecast.append(y_pred)\n",
    "            X = np.concatenate((X[0][1:], y_pred))\n",
    "        return y_scaler.inverse_transform(np.array(forecast).reshape(-1, 1))\n",
    "    \n",
    "    def forecast_lstm_multivariante(self,n_instances:int=7):\n",
    "        model_dir = f'models/{self.stock_name}/LSTM_multivariate_{self.period}_{self.interval}.h5'\n",
    "        model = tf.keras.models.load_model(model_dir)\n",
    "        ## forecast for n hours\n",
    "        forecast = []\n",
    "        data = self.data[['Close', 'High', 'Low', 'Volume']]\n",
    "        data_close = self.data['Close']\n",
    "        df_windowed,df_target = self.window_data_multivariate(data.to_numpy(),data_close.to_numpy().reshape(-1,1),self.window_size)\n",
    "        df_windowed_reshaped = df_windowed.reshape(df_windowed.shape[0], -1)\n",
    "        x_scaler = MinMaxScaler()\n",
    "        x_scaler.fit(df_windowed_reshaped)\n",
    "        df_windowed_reshaped = x_scaler.transform(df_windowed_reshaped)\n",
    "        df_windowed = df_windowed_reshaped.reshape(df_windowed.shape[0], df_windowed.shape[1], df_windowed.shape[2])\n",
    "        y_scaler = MinMaxScaler()\n",
    "        y_scaler.fit(df_target)\n",
    "        df_target = y_scaler.transform(df_target)\n",
    "        X = df_windowed[-1]\n",
    "        for i in range(n_instances):\n",
    "            X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "            y_pred = model.predict(X)\n",
    "            forecast.append(y_pred)\n",
    "            y_pred_expanded = X[-1].copy()  # Use the last timestep as a template\n",
    "            y_pred_expanded[0] = y_pred[0, 0]  # Update the 'Close' feature with the prediction\n",
    "            X = np.concatenate((X[0][1:], y_pred_expanded), axis=0)\n",
    "        return y_scaler.inverse_transform(np.array(forecast).reshape(-1, 1))\n",
    "    \n",
    "    def forecast_mlp_univariate(self,n_instances):\n",
    "        model_dir = f'models/{self.stock_name}/MLP_univaraite_{self.period}_{self.interval}.pkl'\n",
    "        with open(model_dir, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        data_close = self.data['Close']\n",
    "        df_windowed,df_target = self.window_data_univariate(data_close.to_numpy().reshape(-1,1),self.window_size)\n",
    "        df_windowed_reshaped = df_windowed.reshape(df_windowed.shape[0], -1)\n",
    "        x_scaler = MinMaxScaler()\n",
    "        x_scaler.fit(df_windowed_reshaped)\n",
    "        df_windowed_reshaped = x_scaler.transform(df_windowed_reshaped)\n",
    "        df_windowed = df_windowed_reshaped.reshape(df_windowed.shape[0], df_windowed.shape[1], df_windowed.shape[2])\n",
    "        y_scaler = MinMaxScaler()\n",
    "        y_scaler.fit(df_target)\n",
    "        df_target = y_scaler.transform(df_target)\n",
    "        X = df_windowed[-1]\n",
    "        forecast = []\n",
    "        for i in range(n_instances):\n",
    "            y_pred = model.predict(X.reshape(1, -1)).reshape(-1, 1)\n",
    "            forecast.append(y_pred)\n",
    "            X = np.concatenate((X[1:], y_pred))\n",
    "        return y_scaler.inverse_transform(np.array(forecast).reshape(-1, 1))\n",
    "    \n",
    "    \n",
    "    def forecast(self,n_instances:int=7):\n",
    "        return {\n",
    "            'LSTM_univariate':self.forecast_lstm_univariante(n_instances),\n",
    "            'LSTM_multivariate':self.forecast_lstm_multivariante(n_instances),\n",
    "            'MLP_univariate':self.forecast_mlp_univariate(n_instances)\n",
    "        }\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class Predictor:\n",
    "    def __init__(self,interval=\"1h\",period=\"2y\",stocks=['AAPL', 'AMZN', 'GOOGL', 'MSFT', 'TSLA']):\n",
    "        self.stocks = stocks\n",
    "        self.predictors = {}\n",
    "        for stock in stocks:\n",
    "            self.predictors[stock] = StockPredictor(stock_name=stock,interval=interval,period=period)\n",
    "        \n",
    "    def train(self):\n",
    "        for stock in self.predictors.values():\n",
    "            stock.train()\n",
    "    \n",
    "    def forecast(self,n_instances:int=7):\n",
    "        forecast = {}\n",
    "        for stock in self.predictors.values():\n",
    "            forecast[stock.stock_name] = stock.forecast_nhours(n_instances)\n",
    "        return forecast\n",
    "    \n",
    "    def get_current_prices(self):\n",
    "        prices = {}\n",
    "        for stock in self.predictors.values():\n",
    "            prices[stock.stock_name] = stock.get_current_price()\n",
    "        return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "test = StockPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LSTM_univariate': array([[231.8285 ],\n",
       "        [225.64847],\n",
       "        [221.83945],\n",
       "        [218.08871],\n",
       "        [214.93974],\n",
       "        [212.35922],\n",
       "        [209.86719]], dtype=float32),\n",
       " 'LSTM_multivariate': array([[245.01732],\n",
       "        [242.07819],\n",
       "        [241.30177],\n",
       "        [241.36209],\n",
       "        [241.38216],\n",
       "        [241.38513],\n",
       "        [241.38513]], dtype=float32),\n",
       " 'MLP_univariate': array([[242.63043872],\n",
       "        [242.29809363],\n",
       "        [242.30366482],\n",
       "        [242.06716324],\n",
       "        [241.99613415],\n",
       "        [241.80135035],\n",
       "        [241.69864224]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.forecast_nhours()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1736102653.644085"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.now().timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
