{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json bien structur√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Single Subreddit (Fetch Posts Only) ===\n",
      "Fetching page 1 from r/NVDA_Stock (top), time_filter=day ...\n",
      "Fetched 3 posts from r/NVDA_Stock\n",
      " - Microsoft's $80B AI Bet: Data Center Expansion Fuels Nvidia and AMD Surge (ID: 1hsw4wz)\n",
      " - NVDA Swing Holdings üìà (ID: 1hszsor)\n",
      " - The 1 Tech Stock That‚Äôs Actually a Bargain (ID: 1ht3qzo)\n",
      "\n",
      "=== Test 2: Multiple Subreddits (Fetch Posts + Comments) ===\n",
      "Fetching page 1 from r/nvidia (top), time_filter=day ...\n",
      "Fetching page 1 from r/NVDA_Stock (top), time_filter=day ...\n",
      "Fetching comments for post 1ht5avi in r/nvidia ...\n",
      "Fetching comments for post 1hsq0jo in r/nvidia ...\n",
      "Fetching comments for post 1hsw4wz in r/NVDA_Stock ...\n",
      "Fetching comments for post 1hszsor in r/NVDA_Stock ...\n",
      "\n",
      "r/nvidia: 2 posts fetched.\n",
      "  Title: 4070 Ti Super build => 32 comments\n",
      "  Title: 3090 to what? => 101 comments\n",
      "\n",
      "r/NVDA_Stock: 2 posts fetched.\n",
      "  Title: Microsoft's $80B AI Bet: Data Center Expansion Fuels Nvidia and AMD Surge => 7 comments\n",
      "  Title: NVDA Swing Holdings üìà => 10 comments\n",
      "\n",
      "--- Combined Text (Truncated for Demo) ---\n",
      "=== Post #1 ===\n",
      "Title: 4070 Ti Super build\n",
      "Body: Decided to upgrade to my 3070 Ti to an Asus TUF 4070 Ti Super\n",
      "--- Comments (Up to level 2) ---\n",
      "  - (level 1) Comment by trx131: Love that efficient less flashy builds are coming back. This is beautiful op!\n",
      "    - (level 2) Comment by savorymilkman: This is flashy as fuck I'd carry this to a land party in one hand b like \"AYO! 165FPS!\"\n",
      "    - (level 2) Comment by AarshKOK: I swear i don't get the concept of RGB dominated PCs, is this a disco party setup?! I mean I understand aesthetics but why such disco lights man.\n",
      "    - (level 2) Comment by StevoEvo: Thanks\n",
      "    - (level 2) Comment by protector111: Is this tight space efficient? Pretty sure its not. The card is gonna get hot.  If you mean it doesn‚Äôt have 50 rgb fans - then yea.\n",
      "  - (level 1) Comment by Apokolypze: Please say the bottom of that case is vented\n",
      "    - (level 2) Comment by StevoEvo: Yes lol. The NR200p has excellent airflow.\n",
      "  - (level 1) Comment by StevoEvo: Case: Cooler Maste ... [TRUNCATED]\n",
      "\n",
      "=== Test 3: Single Subreddit Search ===\n",
      "Found 2 posts in r/stocks about 'NVDA'\n",
      "   1. $AMD analysis (score: 97)\n",
      "   2. Portfolio in 2025 (score: 52)\n",
      "\n",
      "--- Searched Posts Combined Text (Truncated) ---\n",
      "=== Post #1 ===\n",
      "Title: $AMD analysis\n",
      "Body: [$AMD](https://stocktwits.com/symbol/AMD) analysis:\n",
      "\n",
      "Valuation Check: forward pe in the 25s lower than nvda, growth coming back in 2025, PEG under 1 (peter lynch metric), and EV/Sales under 10.\n",
      "\n",
      "Top CEO Lisa Su\n",
      "\n",
      "Diversification: AMD‚Äôs broader portfolio (CPUs, GPUs, FPGAs with Xilinx acquisition ) provides resilience and growth opportunities. Xilinx provides best in class software for embedded devices opportunity!\n",
      "\n",
      "Potential to Gain Market Share: AMD doesn‚Äôt need to beat Nvidia outright; it just needs to grow its slice of the expanding AI market. AMD is forecasted to grow more than 20% in 2025, and 2026\n",
      "\n",
      "PC refresh cycle and stealing market share from intel should boost revenue!\n",
      "\n",
      "ZT Systems Acquisition: ZT Systems represents AMD's strategic push into hyperscale AI and cloud infrastructure. It enables AMD to deliver integrated solutions combining its hardware with ZT‚Äôs infrastructure expertise.  \n",
      "   \n",
      " $MSFT AI spend in 2025 80 billion: If amd ge ... [TRUNCATED]\n",
      "\n",
      "=== Test 4: Global Search ===\n",
      "Fetched 2 global results about 'NVIDIA'\n",
      "\n",
      "=== Test 5: Global Search, Fetch Comments, Flatten to Text (max_comment_level=2) ===\n",
      "Performing global search for 'NVDA', limit=2, sort=relevance, time_filter=day\n",
      "Fetching comments for post 1hswctz in r/wallstreetbets ...\n",
      "Fetching comments for post 1hszsor in r/NVDA_Stock ...\n",
      "\n",
      "--- Final Combined Text (Truncated for Demo) ---\n",
      "=== Post #1 ===\n",
      "Title: +$723k in NVDA 1DTE gains to start off the year \n",
      "Body: \n",
      "--- Comments (Up to level 2) ---\n",
      "  - (level 1) Comment by VisualMod: \n",
      "**User Report**| | | |\n",
      ":--|:--|:--|:--\n",
      "**Total Submissions** | 10 | **First Seen In WSB** | 4 years ago\n",
      "**Total Comments** | 718 | **Previous Best DD** | \n",
      "**Account Age** | 9 years | | \n",
      "\n",
      "[**Join WSB Discord**](http://discord.gg/wsbverse)\n",
      "  - (level 1) Comment by discobr0: You put 133k in a 1DTE, something tells me this was peanuts to you anyway.\n",
      "    - (level 2) Comment by Baraxton: It‚Äôs like bragging about winning at roulette.\n",
      "    - (level 2) Comment by Cervix-Hammer: How do you even play 0dte calls? Like just by the option 1 day before expiry and hope it goes up? Does it typically have such massive gains 1dte?\n",
      "    - (level 2) Comment by puppymaster123: And assuming he does similar amount three times a week he just recovered all his losses for the last two weeks. But those never made it to wsb tho\n",
      "    - (level 2) Comment by Thin_Zucchini_2 ... [TRUNCATED]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import sys\n",
    "from typing import Union, List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "class RedditScraper:\n",
    "    \"\"\"\n",
    "    A simple class to fetch subreddit posts and comments from Reddit's\n",
    "    (mostly) public JSON endpoints. Suitable for small-scale or personal\n",
    "    usage. For production or large-scale usage, switch to an OAuth-based\n",
    "    approach (e.g., PRAW).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_agent: str = \"MyRedditApp/1.0 (by u/my_username)\",\n",
    "        max_pages: int = 2,\n",
    "        sleep_time: float = 2.0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the RedditScraper.\n",
    "\n",
    "        :param user_agent: Custom User-Agent string to identify your client.\n",
    "        :param max_pages: Default number of 'pages' to paginate for posts.\n",
    "        :param sleep_time: Pause (in seconds) between page fetches to avoid rate-limits.\n",
    "        \"\"\"\n",
    "        self.user_agent = user_agent\n",
    "        self.headers = {\"User-Agent\": self.user_agent}\n",
    "        self.max_pages = max_pages\n",
    "        self.sleep_time = sleep_time\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # (A) Fetching Subreddit Posts\n",
    "    # ---------------------------------------------------------------------\n",
    "    def fetch_subreddit_posts(\n",
    "        self,\n",
    "        subreddits: Union[str, List[str]],\n",
    "        sort: str = \"new\",\n",
    "        limit: int = 25,\n",
    "        max_pages: Optional[int] = None,\n",
    "        time_filter: Optional[str] = None\n",
    "    ) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        Fetch posts from one or more subreddits. Supports pagination and time filtering.\n",
    "\n",
    "        :param subreddits: A single subreddit (string) or list of subreddit names.\n",
    "        :param sort: Sorting criterion (e.g., \"new\", \"hot\", \"top\", \"rising\", \"controversial\").\n",
    "        :param limit: Number of posts to fetch per request (max ~100).\n",
    "        :param max_pages: How many pages to fetch. Defaults to self.max_pages if None.\n",
    "        :param time_filter: Time filter (valid if sort=\"top\" or \"controversial\"), \n",
    "                            e.g., \"day\", \"week\", \"month\", \"year\".\n",
    "        :return: Dictionary where key=subreddit, value=list of post data dicts.\n",
    "        \"\"\"\n",
    "        if isinstance(subreddits, str):\n",
    "            subreddits = [subreddits]  # Wrap in a list for uniform processing\n",
    "\n",
    "        if max_pages is None:\n",
    "            max_pages = self.max_pages\n",
    "\n",
    "        results = {}\n",
    "        for subreddit in subreddits:\n",
    "            all_posts = []\n",
    "            after = None\n",
    "\n",
    "            for page in range(max_pages):\n",
    "                print(f\"Fetching page {page + 1} from r/{subreddit} ({sort}), time_filter={time_filter} ...\")\n",
    "                page_data = self._fetch_subreddit_page(\n",
    "                    subreddit=subreddit,\n",
    "                    sort=sort,\n",
    "                    limit=limit,\n",
    "                    after=after,\n",
    "                    time_filter=time_filter\n",
    "                )\n",
    "\n",
    "                if not page_data:\n",
    "                    # Something went wrong, or no posts returned\n",
    "                    break\n",
    "\n",
    "                all_posts.extend(page_data[\"posts\"])\n",
    "                after = page_data[\"after\"]\n",
    "\n",
    "                if not after:\n",
    "                    # No more pagination\n",
    "                    break\n",
    "\n",
    "                # Sleep to respect rate limits\n",
    "                time.sleep(self.sleep_time)\n",
    "\n",
    "            results[subreddit] = all_posts\n",
    "\n",
    "        return results\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # (B) Fetching Comments for a Specific Post\n",
    "    # ---------------------------------------------------------------------\n",
    "    def fetch_comments_for_post(\n",
    "        self,\n",
    "        subreddit: str,\n",
    "        post_id: str\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Fetch comments for a specific post in a subreddit.\n",
    "        (Does not apply comment depth limitation here; see 'posts_and_comments_to_text'\n",
    "         or your own logic to limit levels if needed.)\n",
    "\n",
    "        :param subreddit: Subreddit name (e.g., \"python\").\n",
    "        :param post_id: The base-36 ID of the post (e.g. \"abc123\").\n",
    "        :return: List of parsed comments, including nested replies.\n",
    "                 Note: Includes *all* comment levels. You may filter later if desired.\n",
    "        \"\"\"\n",
    "        url = f\"https://www.reddit.com/r/{subreddit}/comments/{post_id}.json\"\n",
    "        print(f\"Fetching comments for post {post_id} in r/{subreddit} ...\")\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request error: {e}\")\n",
    "            return []\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: HTTP {response.status_code} for {url}\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "        except ValueError:\n",
    "            print(\"Error parsing JSON response.\")\n",
    "            return []\n",
    "\n",
    "        # data[0] is post info, data[1] is the comment listing\n",
    "        if len(data) < 2:\n",
    "            return []\n",
    "\n",
    "        comments_root = data[1]\n",
    "        comments_list = comments_root.get(\"data\", {}).get(\"children\", [])\n",
    "        parsed_comments = []\n",
    "\n",
    "        for comment in comments_list:\n",
    "            if comment.get(\"kind\") == \"t1\":  # 't1' = comment\n",
    "                parsed_comments.append(self._parse_comment(comment))\n",
    "\n",
    "        return parsed_comments\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # (C) Fetching Both Posts and Comments (Subreddit-level)\n",
    "    # ---------------------------------------------------------------------\n",
    "    def fetch_posts_and_comments(\n",
    "        self,\n",
    "        subreddits: Union[str, List[str]],\n",
    "        sort: str = \"new\",\n",
    "        limit: int = 25,\n",
    "        max_pages: Optional[int] = None,\n",
    "        time_filter: Optional[str] = None\n",
    "    ) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        Convenience method to fetch posts from one or multiple subreddits,\n",
    "        and then fetch comments for each post. Returns a fully nested structure.\n",
    "\n",
    "        :param subreddits: A single subreddit (string) or list of subreddit names.\n",
    "        :param sort: Sorting criterion (e.g., \"new\", \"hot\", \"top\", \"rising\", \"controversial\").\n",
    "        :param limit: Number of posts to fetch per request.\n",
    "        :param max_pages: How many pages to fetch (for each subreddit).\n",
    "        :param time_filter: Time filter (valid if sort=\"top\" or \"controversial\"), e.g., \"day\", \"week\", etc.\n",
    "        :return: {\n",
    "            \"<subreddit>\": [\n",
    "                {\n",
    "                    \"id\": <post_id>,\n",
    "                    \"title\": \"...\",\n",
    "                    \"selftext\": \"...\",\n",
    "                    \"comments\": [ ... list of comments ... ],\n",
    "                    ...\n",
    "                },\n",
    "                ...\n",
    "            ],\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        posts_dict = self.fetch_subreddit_posts(\n",
    "            subreddits=subreddits,\n",
    "            sort=sort,\n",
    "            limit=limit,\n",
    "            max_pages=max_pages,\n",
    "            time_filter=time_filter\n",
    "        )\n",
    "\n",
    "        # Now, fetch comments for each post\n",
    "        for subreddit, posts_list in posts_dict.items():\n",
    "            for post_data in posts_list:\n",
    "                post_id = post_data.get(\"id\")\n",
    "                if post_id:\n",
    "                    comments = self.fetch_comments_for_post(subreddit, post_id)\n",
    "                    post_data[\"comments\"] = comments\n",
    "                else:\n",
    "                    post_data[\"comments\"] = []\n",
    "\n",
    "        return posts_dict\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # (D) Searching Within a Single Subreddit\n",
    "    # ---------------------------------------------------------------------\n",
    "    def search_subreddit_posts(\n",
    "        self,\n",
    "        subreddit: str,\n",
    "        query: str,\n",
    "        sort: str = \"relevance\",\n",
    "        time_filter: Optional[str] = None,\n",
    "        limit: int = 25\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Search a specific subreddit for posts matching a given query.\n",
    "\n",
    "        :param subreddit: The name of the subreddit (e.g., \"python\").\n",
    "        :param query: The search query string (e.g., \"web scraping\").\n",
    "        :param sort: One of ['relevance', 'hot', 'top', 'new', 'comments'].\n",
    "        :param time_filter: Filter posts by time ('hour', 'day', 'week', 'month', 'year', 'all').\n",
    "        :param limit: Number of posts to fetch in one request (up to ~100).\n",
    "        :return: A list of post data dicts.\n",
    "        \"\"\"\n",
    "        base_url = f\"https://www.reddit.com/r/{subreddit}/search.json\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"restrict_sr\": \"1\",   # search only in this subreddit\n",
    "            \"sort\": sort,\n",
    "            \"limit\": limit\n",
    "        }\n",
    "        if time_filter:\n",
    "            params[\"t\"] = time_filter\n",
    "\n",
    "        try:\n",
    "            response = requests.get(base_url, headers=self.headers, params=params)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request error: {e}\")\n",
    "            return []\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: HTTP {response.status_code} for {base_url}\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "        except ValueError:\n",
    "            print(\"Error parsing JSON.\")\n",
    "            return []\n",
    "\n",
    "        posts = []\n",
    "        children = data.get(\"data\", {}).get(\"children\", [])\n",
    "        for child in children:\n",
    "            if child.get(\"kind\") == \"t3\":\n",
    "                post_info = child.get(\"data\", {})\n",
    "                posts.append(post_info)\n",
    "\n",
    "        return posts\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # (E) Global (All-Reddit) Keyword Search\n",
    "    # ---------------------------------------------------------------------\n",
    "    def global_reddit_search(\n",
    "        self,\n",
    "        query: str,\n",
    "        limit: int = 25,\n",
    "        sort: str = \"relevance\",\n",
    "        time_filter: str = \"all\",\n",
    "        after: Optional[str] = None\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Perform a keyword search across ALL of Reddit (unauthenticated).\n",
    "\n",
    "        :param query: The search query (string).\n",
    "        :param limit: Number of search results to fetch (max ~100 per request).\n",
    "        :param sort: Sorting criterion: \"relevance\", \"hot\", \"top\", \"new\", \"comments\".\n",
    "        :param time_filter: Time filter: \"hour\", \"day\", \"week\", \"month\", \"year\", \"all\".\n",
    "        :param after: Pagination token for the next set of results.\n",
    "        :return: A dict with 'results' (list of posts) and 'after' (token to get next page),\n",
    "                 or None if an error occurs.\n",
    "        \"\"\"\n",
    "        base_url = \"https://www.reddit.com/search.json\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"limit\": limit,\n",
    "            \"sort\": sort,\n",
    "            \"t\": time_filter\n",
    "        }\n",
    "        if after:\n",
    "            params[\"after\"] = after\n",
    "\n",
    "        try:\n",
    "            response = requests.get(base_url, headers=self.headers, params=params)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request error: {e}\")\n",
    "            return None\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: HTTP {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "        except ValueError:\n",
    "            print(\"Error parsing JSON.\")\n",
    "            return None\n",
    "\n",
    "        children = data.get(\"data\", {}).get(\"children\", [])\n",
    "        results = []\n",
    "\n",
    "        for child in children:\n",
    "            if child.get(\"kind\") == \"t3\":  # 't3' means it's a post\n",
    "                post_data = child.get(\"data\", {})\n",
    "                results.append(post_data)\n",
    "\n",
    "        after_token = data.get(\"data\", {}).get(\"after\", None)\n",
    "        return {\"results\": results, \"after\": after_token}\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # (F) Search by Keywords, Fetch Comments, Return in Single Structure\n",
    "    # ---------------------------------------------------------------------\n",
    "    def search_keywords_and_get_posts_comments(\n",
    "        self,\n",
    "        query: str,\n",
    "        limit: int = 25,\n",
    "        sort: str = \"relevance\",\n",
    "        time_filter: str = \"all\"\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Global search by keywords, then fetch comments for each post. \n",
    "        Returns a list of post dicts, each including \"comments\".\n",
    "\n",
    "        :param query: The search query.\n",
    "        :param limit: Max results (per fetch). For large numbers, consider paging.\n",
    "        :param sort: \"relevance\", \"hot\", \"top\", \"new\", \"comments\".\n",
    "        :param time_filter: \"hour\", \"day\", \"week\", \"month\", \"year\", \"all\".\n",
    "        :return: A list of posts, each with a nested \"comments\" field.\n",
    "        \"\"\"\n",
    "        print(f\"Performing global search for '{query}', limit={limit}, sort={sort}, time_filter={time_filter}\")\n",
    "        # 1) Perform a single global search call (no pagination here; you can extend if needed).\n",
    "        search_result = self.global_reddit_search(\n",
    "            query=query,\n",
    "            limit=limit,\n",
    "            sort=sort,\n",
    "            time_filter=time_filter\n",
    "        )\n",
    "        if not search_result:\n",
    "            return []\n",
    "\n",
    "        posts = search_result.get(\"results\", [])\n",
    "        # 2) For each post, fetch comments by subreddit/post_id\n",
    "        for post in posts:\n",
    "            subr = post.get(\"subreddit\")\n",
    "            pid = post.get(\"id\")\n",
    "            if subr and pid:\n",
    "                # Fetch comments for each post\n",
    "                comments = self.fetch_comments_for_post(subr, pid)\n",
    "                post[\"comments\"] = comments\n",
    "            else:\n",
    "                post[\"comments\"] = []\n",
    "\n",
    "        return posts\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # (G) Convert Posts (and Nested Comments) to a Single Text String\n",
    "    # ---------------------------------------------------------------------\n",
    "    def posts_and_comments_to_text(\n",
    "        self,\n",
    "        posts_data: List[Dict[str, Any]],\n",
    "        max_comment_level: int = 999\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Flatten/serialize a list of post dicts (each with nested comments)\n",
    "        into a single large text string for easier saving or processing.\n",
    "\n",
    "        :param posts_data: A list of post dicts, each with optional \"comments\" array.\n",
    "        :param max_comment_level: The maximum depth of comment nesting to include.\n",
    "                                  0 means no comments, 1 = only top-level, etc.\n",
    "        :return: A single text string containing posts & comments.\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        for i, post in enumerate(posts_data, start=1):\n",
    "            title = post.get(\"title\", \"[No Title]\")\n",
    "            selftext = post.get(\"selftext\", \"\")\n",
    "            lines.append(f\"=== Post #{i} ===\")\n",
    "            lines.append(f\"Title: {title}\")\n",
    "            lines.append(f\"Body: {selftext}\")\n",
    "\n",
    "            # Convert comments to text, respecting max_comment_level\n",
    "            comments_list = post.get(\"comments\", [])\n",
    "            if max_comment_level > 0 and comments_list:\n",
    "                lines.append(f\"--- Comments (Up to level {max_comment_level}) ---\")\n",
    "                for comment_str in self._flatten_comment_text(\n",
    "                        comments_list, \n",
    "                        current_level=1, \n",
    "                        max_level=max_comment_level):\n",
    "                    lines.append(comment_str)\n",
    "            else:\n",
    "                lines.append(\"--- No Comments (or Comments Suppressed) ---\")\n",
    "\n",
    "            lines.append(\"\\n\")  # Blank line after each post\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def _flatten_comment_text(\n",
    "        self,\n",
    "        comments: List[Dict[str, Any]],\n",
    "        current_level: int,\n",
    "        max_level: int\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Recursively flatten comment trees into a list of strings, respecting max_level.\n",
    "        Skips comments where author=\"[deleted]\" or body=\"[removed]\".\n",
    "\n",
    "        :param comments: List of comment dicts (each may have 'replies').\n",
    "        :param current_level: Current nesting level in the comment tree.\n",
    "        :param max_level: The maximum nesting level to include.\n",
    "        :return: A list of comment lines (strings).\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        if current_level > max_level:\n",
    "            return lines  # stop if we've exceeded desired depth\n",
    "\n",
    "        indent = \"  \" * current_level  # Indentation for readability\n",
    "        for c in comments:\n",
    "            body = c.get(\"body\", \"[No text]\")\n",
    "            author = c.get(\"author\", \"[unknown]\")\n",
    "            if author == \"[deleted]\" or body == \"[removed]\":\n",
    "                # Skip comments that are effectively removed or deleted\n",
    "                continue\n",
    "\n",
    "            # Include this comment\n",
    "            lines.append(f\"{indent}- (level {current_level}) Comment by {author}: {body}\")\n",
    "\n",
    "            replies = c.get(\"replies\", [])\n",
    "            if replies:\n",
    "                # Recurse deeper if we haven't exceeded max_level\n",
    "                lines.extend(\n",
    "                    self._flatten_comment_text(\n",
    "                        replies, \n",
    "                        current_level=current_level + 1, \n",
    "                        max_level=max_level\n",
    "                    )\n",
    "                )\n",
    "        return lines\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    #   Internal Helper Methods for Subreddit Pages & Parsing Comments\n",
    "    # ---------------------------------------------------------------------\n",
    "    def _fetch_subreddit_page(\n",
    "        self,\n",
    "        subreddit: str,\n",
    "        sort: str,\n",
    "        limit: int,\n",
    "        after: Optional[str],\n",
    "        time_filter: Optional[str]\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Fetch a single \"page\" (one HTTP request) of subreddit posts.\n",
    "        Returns None if an error occurs or no data.\n",
    "\n",
    "        :param subreddit: Name of the subreddit (e.g., \"python\").\n",
    "        :param sort: Sorting criterion (e.g., \"new\", \"hot\", \"top\", \"rising\").\n",
    "        :param limit: Number of posts per request (max ~100).\n",
    "        :param after: Pagination token for next page.\n",
    "        :param time_filter: Time filter if sort=\"top\" or \"controversial\" (e.g. \"day\", \"week\", \"month\").\n",
    "        \"\"\"\n",
    "        base_url = f\"https://www.reddit.com/r/{subreddit}/{sort}.json\"\n",
    "        params = {\"limit\": limit}\n",
    "        if after:\n",
    "            params[\"after\"] = after\n",
    "\n",
    "        if time_filter:\n",
    "            params[\"t\"] = time_filter\n",
    "\n",
    "        try:\n",
    "            response = requests.get(base_url, headers=self.headers, params=params)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request error: {e}\")\n",
    "            return None\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: HTTP {response.status_code} for {base_url}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "        except ValueError:\n",
    "            print(\"Error parsing JSON response.\")\n",
    "            return None\n",
    "\n",
    "        children = data.get(\"data\", {}).get(\"children\", [])\n",
    "        posts = []\n",
    "\n",
    "        for child in children:\n",
    "            if child.get(\"kind\") == \"t3\":  # 't3' = post\n",
    "                post_info = child.get(\"data\", {})\n",
    "                posts.append(post_info)\n",
    "\n",
    "        after_token = data.get(\"data\", {}).get(\"after\", None)\n",
    "        return {\n",
    "            \"posts\": posts,\n",
    "            \"after\": after_token\n",
    "        }\n",
    "\n",
    "    def _parse_comment(self, comment_obj: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Recursively parse a comment (and its replies) into a dictionary.\n",
    "        (Does not skip \"[deleted]\" or \"[removed]\" here; skipping logic \n",
    "         is applied later in _flatten_comment_text.)\n",
    "        \"\"\"\n",
    "        comment_data = comment_obj.get(\"data\", {})\n",
    "        comment_id = comment_data.get(\"id\")\n",
    "        comment_author = comment_data.get(\"author\")\n",
    "        comment_body = comment_data.get(\"body\", \"\")\n",
    "        created_utc = comment_data.get(\"created_utc\", 0)\n",
    "\n",
    "        # Recursively parse any replies\n",
    "        replies_obj = comment_data.get(\"replies\")\n",
    "        nested_comments = []\n",
    "        if isinstance(replies_obj, dict):  # sometimes 'replies' can be an empty string\n",
    "            children = replies_obj.get(\"data\", {}).get(\"children\", [])\n",
    "            for child in children:\n",
    "                if child.get(\"kind\") == \"t1\":\n",
    "                    nested_comments.append(self._parse_comment(child))\n",
    "\n",
    "        return {\n",
    "            \"comment_id\": comment_id,\n",
    "            \"author\": comment_author,\n",
    "            \"body\": comment_body,\n",
    "            \"created_utc\": created_utc,\n",
    "            \"replies\": nested_comments,\n",
    "        }\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Example Usage / Test Cases\n",
    "# ---------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        scraper = RedditScraper(\n",
    "            user_agent=\"MyRedditApp/1.0 (by u/my_username)\",\n",
    "            max_pages=1,\n",
    "            sleep_time=1.5\n",
    "        )\n",
    "\n",
    "        ##########\n",
    "        print(\"=== Test 1: Single Subreddit (Fetch Posts Only) ===\")\n",
    "        single_sub_data = scraper.fetch_subreddit_posts(\n",
    "            subreddits=\"NVDA_Stock\",\n",
    "            sort=\"top\",\n",
    "            time_filter=\"day\",\n",
    "            limit=3,\n",
    "        )\n",
    "        print(f\"Fetched {len(single_sub_data['NVDA_Stock'])} posts from r/NVDA_Stock\")\n",
    "        for post in single_sub_data[\"NVDA_Stock\"]:\n",
    "            print(f\" - {post.get('title')} (ID: {post.get('id')})\")\n",
    "        \n",
    "        ##########\n",
    "        print(\"\\n=== Test 2: Multiple Subreddits (Fetch Posts + Comments) ===\")\n",
    "        multi_sub_data = scraper.fetch_posts_and_comments(\n",
    "            subreddits=[\"nvidia\", \"NVDA_Stock\"],\n",
    "            sort=\"top\",\n",
    "            time_filter=\"day\",\n",
    "            limit=2,\n",
    "            max_pages=1  # just 1 page each for brevity\n",
    "        )\n",
    "        for subr, posts in multi_sub_data.items():\n",
    "            print(f\"\\nr/{subr}: {len(posts)} posts fetched.\")\n",
    "            for p in posts:\n",
    "                print(f\"  Title: {p.get('title')} => {len(p.get('comments', []))} comments\")\n",
    "\n",
    "        # ------------------------------------------\n",
    "        # CORRECTION:\n",
    "        # To generate combined text for ALL subreddits, first collect all posts in one list.\n",
    "        # ------------------------------------------\n",
    "        all_posts = []\n",
    "        for subr, posts in multi_sub_data.items():\n",
    "            all_posts.extend(posts)\n",
    "\n",
    "        combined_text = scraper.posts_and_comments_to_text(all_posts, max_comment_level=2)\n",
    "        print(\"\\n--- Combined Text (Truncated for Demo) ---\")\n",
    "        print(combined_text[:1000], \"... [TRUNCATED]\")\n",
    "\n",
    "\n",
    "        ##########\n",
    "        print(\"\\n=== Test 3: Single Subreddit Search ===\")\n",
    "        srch_results = scraper.search_subreddit_posts(\n",
    "            subreddit=\"stocks\",\n",
    "            query=\"NVDA\",\n",
    "            sort=\"top\",\n",
    "            time_filter=\"week\",\n",
    "            limit=2\n",
    "        )\n",
    "        print(f\"Found {len(srch_results)} posts in r/stocks about 'NVDA'\")\n",
    "        for i, post in enumerate(srch_results, start=1):\n",
    "            print(f\"   {i}. {post.get('title')} (score: {post.get('score')})\")\n",
    "\n",
    "        # You can flatten these search results into a single text as well:\n",
    "        srch_text = scraper.posts_and_comments_to_text(srch_results, max_comment_level=2)\n",
    "        print(\"\\n--- Searched Posts Combined Text (Truncated) ---\")\n",
    "        print(srch_text[:1000], \"... [TRUNCATED]\")      \n",
    "\n",
    "\n",
    "        ##########\n",
    "        print(\"\\n=== Test 4: Global Search ===\")\n",
    "        global_res = scraper.global_reddit_search(\n",
    "            query=\"NVIDIA\",\n",
    "            limit=2,\n",
    "            sort=\"relevance\",\n",
    "            time_filter=\"day\"\n",
    "        )\n",
    "        if global_res:\n",
    "            print(f\"Fetched {len(global_res['results'])} global results about 'NVIDIA'\")\n",
    "\n",
    "        print(\"\\n=== Test 5: Global Search, Fetch Comments, Flatten to Text (max_comment_level=2) ===\")\n",
    "        posts_with_comments = scraper.search_keywords_and_get_posts_comments(\n",
    "            query=\"NVDA\",\n",
    "            limit=2,\n",
    "            sort=\"relevance\",\n",
    "            time_filter=\"day\"\n",
    "        )\n",
    "        \n",
    "        # Now parse into a single text string, limiting to 2 levels of nested comments.\n",
    "        final_text = scraper.posts_and_comments_to_text(posts_with_comments, max_comment_level=2)\n",
    "        print(\"\\n--- Final Combined Text (Truncated for Demo) ---\")\n",
    "        print(final_text[:1000], \"... [TRUNCATED]\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nScript interrupted by user.\")\n",
    "        sys.exit(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing global search for 'NVDA', limit=2, sort=relevance, time_filter=day\n",
      "Fetching comments for post 1hswctz in r/wallstreetbets ...\n",
      "Fetching comments for post 1hszsor in r/NVDA_Stock ...\n",
      "{'posts': [{'title': '+$723k in NVDA 1DTE gains to start off the year', 'body': '', 'subreddit': 'unknown', 'comments': [{'level': 1, 'author': 'VisualMod', 'content': '**User Report**| | | | :--|:--|:--|:-- **Total Submissions** | 10 | **First Seen In WSB** | 4 years ago **Total Comments** | 718 | **Previous Best DD** | **Account Age** | 9 years | | [**Join WSB Discord**]', 'replies': []}, {'level': 1, 'author': 'discobr0', 'content': 'You put 133k in a 1DTE, something tells me this was peanuts to you anyway. - (level 2) Comment by Baraxton: It‚Äôs like bragging about winning at roulette. - (level 2) Comment by Cervix-Hammer: How do you even play 0dte calls? Like just by the option 1 day before expiry and hope it goes up? Does it typically have such massive gains 1dte? - (level 2) Comment by puppymaster123: And assuming he does similar amount three times a week he just recovered all his losses for the last two weeks. But those never made it to wsb tho - (level 2) Comment by Thin_Zucchini_2677: Same way you buy and sell stocks. Watch your 1m indicators and buy at low rsi macd divergence and wait - (level 2) Comment by AcanthisittaEasy5878: This 100%, or not his money - (level 2) Comment by Warchief_X: look at his post history lol. 133k is absolute absolute peanut to him - (level 2) Comment by RepresentativeWay779: If you never go Big you never win big', 'replies': []}, {'level': 1, 'author': '314159bits', 'content': \"How tf did you know it would pump like this today - (level 2) Comment by PercyPeru: He didn‚Äôt. Thats the magic - (level 2) Comment by Nanas_700k: He might not have expected such a move, but once he was on the right side of the trade he let his winners run as many good traders knows to do - (level 2) Comment by moistpimplee: he gambled. hes also rich as fuck. so it doesn't matter - (level 2) Comment by MostRadiant: I am guessing he believed stocks not influenced by China recession would recover quickly. - (level 2) Comment by fliesenschieber: He's an expert - (level 2) Comment by reddit-abcde: He is an insider\", 'replies': []}, {'level': 1, 'author': 'J82nd', 'content': 'I sold 1 covered call 0dte 145 made $27.34 after fee. Not sure how everyone is buying over 100 calls unless you have a multi million dollar account. - (level 2) Comment by collegegirlsgw: Bingo lol that‚Äôs exactly what this guy has - (level 2) Comment by DrunkRespondent: Easy, just buy naked.', 'replies': []}, {'level': 1, 'author': 'NYGBobby', 'content': 'Rich guy gets richer cool - (level 2) Comment by whatisthereallife: \"Just git gud scrub\" - rich people - (level 2) Comment by main135: that\\'s how it works - (level 2) Comment by fuzzywuzzy123: I love happy endings!', 'replies': []}, {'level': 1, 'author': 'Evander85', 'content': \"I would have sold this position when it was up 5% which is why I‚Äôm a Brokie - (level 2) Comment by Ok_Battle_4082: Reminder that you don‚Äôt see the other x amount of trades that this guy probably lost the same amount or more on - (level 2) Comment by e2can: A wins a win - (level 2) Comment by Mycatspiss: OP a trust fund kid which is why he didn't sell. Don't beat yourself up\", 'replies': []}, {'level': 1, 'author': 'Kekulzor', 'content': 'Dad, I finally found you after all these years - (level 2) Comment by wedditmod: Brother?', 'replies': []}, {'level': 1, 'author': 'buddumz', 'content': 'https://preview.redd.it/dlw46c1revae1.jpeg?width=654&amp;format=pjpg&amp;auto=webp&amp;s=b254e851e7531199ade8e1bc37764519fe30aa80 I was in this too üòé', 'replies': []}, {'level': 1, 'author': 'A_and_P_Armory', 'content': 'The 320 calls today had a 100x low to high (0.20 to 20.00). That‚Äôs crazy. Real world potential gain there. I‚Äôm up 5200% in an option now (over several months of holding), but 10,000% range in a day is crazy nice. Congrats for putting your nuts out there. - (level 2) Comment by crankthehandle: yeah, 5200% sucks big times - (level 2) Comment by mikeysd123: To be fair theres 100x plays almost every day on 0DTEs - (level 2) Comment by Ill_Cancel4937: Lol what option and stock do you have that much faith in to hold a 52 bagger?', 'replies': []}, {'level': 1, 'author': 'convexdominance6', 'content': \"Bought yesterday and sold throughout the day today. MSTR post to follow next week :) - (level 2) Comment by soploping: How long did it take u to acquire this amount of wealth - (level 2) Comment by youngkeet: Oh i am excited for this. I went full port and lost my ass tbh......sold at 419 after buying $460ish and then again at 490 Thats the difference between me and you. Im ACTUALLY regarded - (level 2) Comment by NyCWalker76: Which broker is this? - (level 2) Comment by TarzanSwingTrades: MSTR calls or puts? - (level 2) Comment by HappyCurrencies: what's the most you've lost in a trade?\", 'replies': []}, {'level': 1, 'author': '2toneSound', 'content': 'Teach me master üôè', 'replies': []}, {'level': 1, 'author': 'LowCryptographer9047', 'content': 'I remember this guy ‚Äúthe son of jack dorsey‚Äù not his first big win', 'replies': []}, {'level': 1, 'author': 'danlyh', 'content': 'putting over 100k into 1DTE options huh https://preview.redd.it/doxilsbmuuae1.jpeg?width=1179&amp;format=pjpg&amp;auto=webp&amp;s=c83dca1e7d268a35dbf904f4bc5dc226e4fdc4a0 - (level 2) Comment by IVcrushonYou: Beat me to it. ü§£', 'replies': []}, {'level': 1, 'author': 'lovesToClap', 'content': 'guy has insane gains in his post history...wtf - (level 2) Comment by LoDyes: 1.2 mil in a day..', 'replies': []}, {'level': 1, 'author': 'bluecgene', 'content': 'This is Warren Buffett on his play account‚Ä¶ enjoying the last moments', 'replies': []}, {'level': 1, 'author': 'Glittering_Poetry_60', 'content': 'You have 2k of my money. Congrats you glorious bastard', 'replies': []}, {'level': 1, 'author': 'DeepestWinterBlue', 'content': 'Disgustingly bold move', 'replies': []}, {'level': 1, 'author': 'DepartmentBig2849', 'content': 'üê≥', 'replies': []}, {'level': 1, 'author': 'ericz0r', 'content': 'Now share the rest of your weekly options plays for the last week too. - (level 2) Comment by rain168: Didn‚Äôt he also buy 1.3M calls on SPXW that expired worthless today? He‚Äôs obviously rich, so all these are just play money.', 'replies': []}, {'level': 1, 'author': 'Intelligent_Flan_571', 'content': 'This bro is always pulling off these 1-3DTE plays ‚Ä¶is he the chosen one or is he hiding his 7 digit losses from us ü§®', 'replies': []}, {'level': 1, 'author': 'miktoo', 'content': 'what a way to start the year', 'replies': []}, {'level': 1, 'author': 'missmypinto', 'content': 'Should‚Äôve bought TSLA 0dTE you‚Äôd have made about 3.5 mil', 'replies': []}, {'level': 1, 'author': 'urpapi_1', 'content': 'What the flying fu‚Ä¶‚Ä¶‚Ä¶ üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´', 'replies': []}, {'level': 1, 'author': 'Junesathon', 'content': 'U need my flair', 'replies': []}, {'level': 1, 'author': 'n0Drip', 'content': 'üêêactivity', 'replies': []}, {'level': 1, 'author': 'CatDadd0', 'content': 'Lol I was happy with my 700 dollar gain on my monthly contracts for Nvidia, this is absolute insanity', 'replies': []}, {'level': 1, 'author': 'ProtectUrNeckWU', 'content': 'Do it again big shot', 'replies': []}, {'level': 1, 'author': 'youngkeet', 'content': 'Let me hold a dollar... jk but this is big dick shit i gotta say. Well done', 'replies': []}, {'level': 1, 'author': 'DeadByOptions', 'content': 'What was the cost of each contract?', 'replies': []}, {'level': 1, 'author': 'Dontknowgoat', 'content': 'I usually use my extra millions to get my fire started. üòÇüòÇüòÇI don‚Äôt do 1DTE. Why waste it on a gamble. Least get some heat. üòÇ', 'replies': []}, {'level': 1, 'author': 'Kenneessyy', 'content': 'Congratulations!!', 'replies': []}, {'level': 1, 'author': 'methylaminebb', 'content': 'okay this guy is starting to piss me off', 'replies': []}, {'level': 1, 'author': 'Oxy_Moronico', 'content': 'I accept tips and bribes.', 'replies': []}, {'level': 1, 'author': 'GetOffYoAssBro', 'content': 'Anyone could do that if they have your money!', 'replies': []}, {'level': 1, 'author': 'StrongDongKong', 'content': '!(emote|t5_2th52|4276)', 'replies': []}, {'level': 1, 'author': 'NigerianPrinceClub', 'content': 'wtf lol', 'replies': []}, {'level': 1, 'author': 'cryptoislife_k', 'content': 'brother what the fuck is your chatgpt 5 telling you to make such plays holy', 'replies': []}, {'level': 1, 'author': 'chadcultist', 'content': 'Welp, time for only disappointment. Good job busting your yearly nut before the end of January. !(emote|t5_2th52|12787)', 'replies': []}, {'level': 1, 'author': 'Snowballeffects', 'content': 'Wowwwwwwww', 'replies': []}, {'level': 1, 'author': 'Truman_Show_1984', 'content': \"Why don't you start posting WHEN YOU BUY and NEAR SALE TIME. I'm getting a little suspicious about all of these afters.\", 'replies': []}, {'level': 1, 'author': 'Willoni_23', 'content': 'Damn!', 'replies': []}, {'level': 1, 'author': 'EmployNeat8745', 'content': 'Holy shmoly', 'replies': []}, {'level': 1, 'author': 'NuggetBattalion', 'content': 'What the actual bleep!', 'replies': []}, {'level': 1, 'author': 'mrtomd', 'content': 'How did you decide to do these trades? What was the trigger?', 'replies': []}, {'level': 1, 'author': 'gwar11', 'content': 'Damn. I need a beer!', 'replies': []}, {'level': 1, 'author': 'd33p7r0ubl3', 'content': 'Have mods verified whether these are real posts?', 'replies': []}, {'level': 1, 'author': 'No_Art5533', 'content': 'teach me your ways üôå', 'replies': []}, {'level': 1, 'author': 'Tylord96', 'content': 'I put in a single mstr call at 300 made almost 4K on it. I wish I just yolod my account on it, but 99/100 times I‚Äôd lose that money. Hindsight is 20/20', 'replies': []}, {'level': 1, 'author': 'ManBearPig_1983', 'content': 'NVDA or bust!', 'replies': []}, {'level': 1, 'author': 'dadscallion', 'content': 'You‚Äôre either stupid or rich or both. This is how people blow accounts.', 'replies': []}, {'level': 1, 'author': 'Ashamed_Distance_144', 'content': 'You should just take the rest of the year off and chill in SPY.', 'replies': []}, {'level': 1, 'author': 'Ok_Pea_3376', 'content': 'That‚Äôs my lucky number', 'replies': []}, {'level': 1, 'author': 'Im_Fr3aKiN_0uT', 'content': \"Dog you didn't sell did you? That IV is about to shoot through the roof. If you held you'll double profits from IV alone.\", 'replies': []}, {'level': 1, 'author': 'elmajico101', 'content': 'Long time lurker. How tf do I learn this? Idk anything about trading, anywhere to start?', 'replies': []}, {'level': 1, 'author': 'BullfrogTechnical273', 'content': 'I probably sold you some of these because I‚Äôm ultra regarded !(emote|free_emotes_pack|sob)', 'replies': []}, {'level': 1, 'author': 'grabGPT', 'content': 'Your gains and nuts are alike. Uptight', 'replies': []}, {'level': 1, 'author': 'TFC_OG', 'content': 'How are the gains always happening when you post after the fact and losses happen when you call trades real time, tho?', 'replies': []}, {'level': 1, 'author': 'DOGEtothemoon21', 'content': 'How much money would you need to have to gamble in such crazy ways ? Edit: typo', 'replies': []}, {'level': 1, 'author': 'Catatafeesh1', 'content': 'This man probably just made like a trillion dollars. Fuck.', 'replies': []}, {'level': 1, 'author': 'Professor_Meteor', 'content': 'Damn! That‚Äôs dope', 'replies': []}, {'level': 1, 'author': 'joemacross', 'content': 'holy shit', 'replies': []}, {'level': 1, 'author': 'whatscookin33', 'content': 'At some point the probabilities will work against you. I‚Äôll be waiting for the $0 account post üòÇ', 'replies': []}, {'level': 1, 'author': 'xaero57', 'content': 'Jesus christ I only have 6k to invest', 'replies': []}, {'level': 1, 'author': 'StockMoeller', 'content': 'What platform are you using for a trade like this? Mine doesn‚Äôt even have 0DTE or LEAPS', 'replies': []}, {'level': 1, 'author': 'D4Junkie', 'content': 'This post told me I‚Äôm poor in 8 different ways‚Ä¶', 'replies': []}]}, {'title': 'NVDA Swing Holdings üìà', 'body': 'My current NVDA holdings. What are your thoughts for next week? Sold half at $138 but now wondering how far will this ride go.', 'subreddit': 'unknown', 'comments': [{'level': 1, 'author': 'tnguyen5057', 'content': 'CES with Jensen on Monday, Cerence (CRNC) announced collaboration with NVDA today, MSFT announced investing at least 80 billion more in AI infrastructure, and PMI (economic data) beats estimates today. NVDA going up - (level 2) Comment by PlaybookTrading: Thanks for the valuable info brother üôè - (level 2) Comment by sockchaser: Nice summary!', 'replies': []}, {'level': 1, 'author': 'Zoso843', 'content': 'Any chance in hell we will be at $150 by the 10th? üëÄ - (level 2) Comment by PlaybookTrading: I wouldn‚Äôt buy an options for $150 but I do hope for that. - (level 2) Comment by Jcoronado92: I feel like shit. Sold a call for 1/10 138 strike. They will be called away next Friday. 3.2k premium for 8 contracts - (level 2) Comment by Dav1dBee: Of course no. It will get shorted soon. - (level 2) Comment by Dieseltrain760: No', 'replies': []}, {'level': 1, 'author': 'masterpiece77', 'content': 'My parents used to swing and throw swinger parties but we aren‚Äôt rich so they must not of been good at it. - (level 2) Comment by PlaybookTrading: Thought I was in the wrong reddit channel üò≥üòÇ', 'replies': []}, {'level': 1, 'author': 'Electrical_Green_258', 'content': 'Crnc sure going down on Monday.. Too much increase in a day today', 'replies': []}, {'level': 1, 'author': 'messengers1', 'content': 'My 15k won‚Äôt come until Jan. 14. Please don‚Äôt go up too high or dip lower so I can get my hand on 100 shares. - (level 2) Comment by Prince_Derrick101: Same.', 'replies': []}, {'level': 1, 'author': 'CG_throwback', 'content': 'Not swinging for less than 146-148.', 'replies': []}, {'level': 1, 'author': 'dacalo', 'content': 'Sold my leveraged positions today like LEAPS and NVDL for a nice profit. Still holding shares. If it goes up, great. If it drops, will buy more and repeat again.', 'replies': []}, {'level': 1, 'author': 'kansai828', 'content': 'Let me know when is $500', 'replies': []}, {'level': 1, 'author': 'Artistic_Original_88', 'content': \"The AI business is growing and I'm holding.\", 'replies': []}]}]}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "class RedditParser:\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "        self.posts = []\n",
    "\n",
    "    def extract_comments(self, comment_section: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract comments from a comment section.\n",
    "        Returns a list of comment dictionaries with level, author, and content.\n",
    "        \"\"\"\n",
    "        comments = []\n",
    "        comment_pattern = r'\\(level (\\d+)\\) Comment by (\\w+): (.*?)(?=(?:\\n  - \\(level|\\Z))'\n",
    "        \n",
    "        for match in re.finditer(comment_pattern, comment_section, re.DOTALL):\n",
    "            level = int(match.group(1))\n",
    "            author = match.group(2)\n",
    "            content = self.clean_text(match.group(3))\n",
    "            \n",
    "            comment = {\n",
    "                'level': level,\n",
    "                'author': author,\n",
    "                'content': content,\n",
    "                'replies': []  # Will be populated for nested comments\n",
    "            }\n",
    "            comments.append(comment)\n",
    "\n",
    "        # Organize comments into a tree structure\n",
    "        comment_tree = []\n",
    "        comment_stack = []\n",
    "        \n",
    "        for comment in comments:\n",
    "            while comment_stack and comment['level'] <= comment_stack[-1]['level']:\n",
    "                comment_stack.pop()\n",
    "                \n",
    "            if comment_stack:\n",
    "                comment_stack[-1]['replies'].append(comment)\n",
    "            else:\n",
    "                comment_tree.append(comment)\n",
    "                \n",
    "            comment_stack.append(comment)\n",
    "\n",
    "        return comment_tree\n",
    "\n",
    "    def extract_posts(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract posts and their comments from the text.\n",
    "        Returns a list of dictionaries containing post information and comments.\n",
    "        \"\"\"\n",
    "        # Split the text into sections based on \"=== Post\"\n",
    "        post_sections = re.split(r'=== Post #\\d+ ===', self.text)\n",
    "        \n",
    "        # Remove any empty sections\n",
    "        post_sections = [section.strip() for section in post_sections if section.strip()]\n",
    "\n",
    "        for section in post_sections:\n",
    "            post_data = {}\n",
    "            \n",
    "            # Extract title\n",
    "            title_match = re.search(r'Title: (.*?)(?:\\nBody:|$)', section, re.DOTALL)\n",
    "            if title_match:\n",
    "                post_data['title'] = title_match.group(1).strip()\n",
    "\n",
    "            # Extract body\n",
    "            body_match = re.search(r'Body: (.*?)(?:---|\\Z)', section, re.DOTALL)\n",
    "            if body_match:\n",
    "                post_data['body'] = body_match.group(1).strip()\n",
    "            else:\n",
    "                post_data['body'] = \"\"\n",
    "\n",
    "            # Extract subreddit\n",
    "            subreddit_match = re.search(r'(?:from|in) r/(\\w+)', section)\n",
    "            if subreddit_match:\n",
    "                post_data['subreddit'] = subreddit_match.group(1)\n",
    "            else:\n",
    "                # If no subreddit found in the section, try to find it in the larger context\n",
    "                subreddit_match = re.search(r'(?:from|in) r/(\\w+)', self.text)\n",
    "                if subreddit_match:\n",
    "                    post_data['subreddit'] = subreddit_match.group(1)\n",
    "                else:\n",
    "                    post_data['subreddit'] = \"unknown\"\n",
    "\n",
    "            # Extract comments\n",
    "            comments_section_match = re.search(r'--- Comments \\(Up to level \\d+\\) ---\\n(.*?)(?=(?:\\n===|\\Z))', section, re.DOTALL)\n",
    "            if comments_section_match:\n",
    "                comments_text = comments_section_match.group(1)\n",
    "                post_data['comments'] = self.extract_comments(comments_text)\n",
    "            else:\n",
    "                post_data['comments'] = []\n",
    "\n",
    "            if post_data.get('title'):  # Only add if we at least have a title\n",
    "                self.posts.append(post_data)\n",
    "\n",
    "        return self.posts\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean the text by removing extra whitespace and special characters.\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        # Remove any special Reddit formatting\n",
    "        text = re.sub(r'\\[\\w+\\]|\\(http[s]?://[^\\)]+\\)', '', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def process_and_save(self) -> None:\n",
    "        \"\"\"\n",
    "        Process the text and save the results to a JSON file.\n",
    "        \"\"\"\n",
    "        # Extract and clean the posts\n",
    "        posts = self.extract_posts()\n",
    "        \n",
    "        # Clean the text in each post\n",
    "        for post in posts:\n",
    "            post['title'] = self.clean_text(post['title'])\n",
    "            post['body'] = self.clean_text(post['body'])\n",
    "\n",
    "        # Save to JSON file\n",
    "        # with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        #     json.dump({'posts': posts}, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        return {\n",
    "            'posts': posts\n",
    "        }\n",
    "\n",
    "def get_and_parse():\n",
    "    # Read the input file\n",
    "    # with open('output.txt', 'r', encoding='utf-8') as f:\n",
    "    #     text = f.read()\n",
    "\n",
    "    scraper = RedditScraper(\n",
    "        user_agent=\"MyRedditApp/1.0 (by u/my_username)\",\n",
    "        max_pages=1,\n",
    "        sleep_time=1.5\n",
    "    )\n",
    "    \n",
    "    # Fetch posts and comments\n",
    "    posts_with_comments = scraper.search_keywords_and_get_posts_comments(\n",
    "            query=\"NVDA\",\n",
    "            limit=2,\n",
    "            sort=\"relevance\",\n",
    "            time_filter=\"day\"\n",
    "    )\n",
    "    # Combine posts and comments into a single text\n",
    "    text = scraper.posts_and_comments_to_text(posts_with_comments, max_comment_level=2)\n",
    "\n",
    "    # Create parser instance\n",
    "    parser = RedditParser(text)\n",
    "    \n",
    "    text_parsed = parser.process_and_save()\n",
    "    print(text_parsed)\n",
    "    \n",
    "    # Process and save to JSON\n",
    "    # parser.process_and_save('reddit_posts.json')\n",
    "    return text_parsed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_and_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing VADER sentiment analyzer...\n",
      "Loading Reddit data...\n",
      "Performing global search for 'NVDA', limit=2, sort=relevance, time_filter=day\n",
      "Fetching comments for post 1hswctz in r/wallstreetbets ...\n",
      "Fetching comments for post 1hszsor in r/NVDA_Stock ...\n",
      "{'posts': [{'title': '+$723k in NVDA 1DTE gains to start off the year', 'body': '', 'subreddit': 'unknown', 'comments': [{'level': 1, 'author': 'VisualMod', 'content': '**User Report**| | | | :--|:--|:--|:-- **Total Submissions** | 10 | **First Seen In WSB** | 4 years ago **Total Comments** | 718 | **Previous Best DD** | **Account Age** | 9 years | | [**Join WSB Discord**]', 'replies': []}, {'level': 1, 'author': 'discobr0', 'content': 'You put 133k in a 1DTE, something tells me this was peanuts to you anyway. - (level 2) Comment by Baraxton: It‚Äôs like bragging about winning at roulette. - (level 2) Comment by Cervix-Hammer: How do you even play 0dte calls? Like just by the option 1 day before expiry and hope it goes up? Does it typically have such massive gains 1dte? - (level 2) Comment by puppymaster123: And assuming he does similar amount three times a week he just recovered all his losses for the last two weeks. But those never made it to wsb tho - (level 2) Comment by Thin_Zucchini_2677: Same way you buy and sell stocks. Watch your 1m indicators and buy at low rsi macd divergence and wait - (level 2) Comment by AcanthisittaEasy5878: This 100%, or not his money - (level 2) Comment by Warchief_X: look at his post history lol. 133k is absolute absolute peanut to him - (level 2) Comment by RepresentativeWay779: If you never go Big you never win big', 'replies': []}, {'level': 1, 'author': '314159bits', 'content': \"How tf did you know it would pump like this today - (level 2) Comment by PercyPeru: He didn‚Äôt. Thats the magic - (level 2) Comment by Nanas_700k: He might not have expected such a move, but once he was on the right side of the trade he let his winners run as many good traders knows to do - (level 2) Comment by moistpimplee: he gambled. hes also rich as fuck. so it doesn't matter - (level 2) Comment by MostRadiant: I am guessing he believed stocks not influenced by China recession would recover quickly. - (level 2) Comment by fliesenschieber: He's an expert - (level 2) Comment by reddit-abcde: He is an insider\", 'replies': []}, {'level': 1, 'author': 'J82nd', 'content': 'I sold 1 covered call 0dte 145 made $27.34 after fee. Not sure how everyone is buying over 100 calls unless you have a multi million dollar account. - (level 2) Comment by collegegirlsgw: Bingo lol that‚Äôs exactly what this guy has - (level 2) Comment by DrunkRespondent: Easy, just buy naked.', 'replies': []}, {'level': 1, 'author': 'NYGBobby', 'content': 'Rich guy gets richer cool - (level 2) Comment by whatisthereallife: \"Just git gud scrub\" - rich people - (level 2) Comment by main135: that\\'s how it works - (level 2) Comment by fuzzywuzzy123: I love happy endings!', 'replies': []}, {'level': 1, 'author': 'Evander85', 'content': \"I would have sold this position when it was up 5% which is why I‚Äôm a Brokie - (level 2) Comment by Ok_Battle_4082: Reminder that you don‚Äôt see the other x amount of trades that this guy probably lost the same amount or more on - (level 2) Comment by e2can: A wins a win - (level 2) Comment by Mycatspiss: OP a trust fund kid which is why he didn't sell. Don't beat yourself up\", 'replies': []}, {'level': 1, 'author': 'Kekulzor', 'content': 'Dad, I finally found you after all these years - (level 2) Comment by wedditmod: Brother?', 'replies': []}, {'level': 1, 'author': 'buddumz', 'content': 'https://preview.redd.it/dlw46c1revae1.jpeg?width=654&amp;format=pjpg&amp;auto=webp&amp;s=b254e851e7531199ade8e1bc37764519fe30aa80 I was in this too üòé', 'replies': []}, {'level': 1, 'author': 'A_and_P_Armory', 'content': 'The 320 calls today had a 100x low to high (0.20 to 20.00). That‚Äôs crazy. Real world potential gain there. I‚Äôm up 5200% in an option now (over several months of holding), but 10,000% range in a day is crazy nice. Congrats for putting your nuts out there. - (level 2) Comment by crankthehandle: yeah, 5200% sucks big times - (level 2) Comment by mikeysd123: To be fair theres 100x plays almost every day on 0DTEs - (level 2) Comment by Ill_Cancel4937: Lol what option and stock do you have that much faith in to hold a 52 bagger?', 'replies': []}, {'level': 1, 'author': 'convexdominance6', 'content': \"Bought yesterday and sold throughout the day today. MSTR post to follow next week :) - (level 2) Comment by soploping: How long did it take u to acquire this amount of wealth - (level 2) Comment by youngkeet: Oh i am excited for this. I went full port and lost my ass tbh......sold at 419 after buying $460ish and then again at 490 Thats the difference between me and you. Im ACTUALLY regarded - (level 2) Comment by NyCWalker76: Which broker is this? - (level 2) Comment by TarzanSwingTrades: MSTR calls or puts? - (level 2) Comment by HappyCurrencies: what's the most you've lost in a trade?\", 'replies': []}, {'level': 1, 'author': '2toneSound', 'content': 'Teach me master üôè', 'replies': []}, {'level': 1, 'author': 'LowCryptographer9047', 'content': 'I remember this guy ‚Äúthe son of jack dorsey‚Äù not his first big win', 'replies': []}, {'level': 1, 'author': 'danlyh', 'content': 'putting over 100k into 1DTE options huh https://preview.redd.it/doxilsbmuuae1.jpeg?width=1179&amp;format=pjpg&amp;auto=webp&amp;s=c83dca1e7d268a35dbf904f4bc5dc226e4fdc4a0 - (level 2) Comment by IVcrushonYou: Beat me to it. ü§£', 'replies': []}, {'level': 1, 'author': 'lovesToClap', 'content': 'guy has insane gains in his post history...wtf - (level 2) Comment by LoDyes: 1.2 mil in a day..', 'replies': []}, {'level': 1, 'author': 'bluecgene', 'content': 'This is Warren Buffett on his play account‚Ä¶ enjoying the last moments', 'replies': []}, {'level': 1, 'author': 'Glittering_Poetry_60', 'content': 'You have 2k of my money. Congrats you glorious bastard', 'replies': []}, {'level': 1, 'author': 'DeepestWinterBlue', 'content': 'Disgustingly bold move', 'replies': []}, {'level': 1, 'author': 'DepartmentBig2849', 'content': 'üê≥', 'replies': []}, {'level': 1, 'author': 'ericz0r', 'content': 'Now share the rest of your weekly options plays for the last week too. - (level 2) Comment by rain168: Didn‚Äôt he also buy 1.3M calls on SPXW that expired worthless today? He‚Äôs obviously rich, so all these are just play money.', 'replies': []}, {'level': 1, 'author': 'Intelligent_Flan_571', 'content': 'This bro is always pulling off these 1-3DTE plays ‚Ä¶is he the chosen one or is he hiding his 7 digit losses from us ü§®', 'replies': []}, {'level': 1, 'author': 'miktoo', 'content': 'what a way to start the year', 'replies': []}, {'level': 1, 'author': 'missmypinto', 'content': 'Should‚Äôve bought TSLA 0dTE you‚Äôd have made about 3.5 mil', 'replies': []}, {'level': 1, 'author': 'urpapi_1', 'content': 'What the flying fu‚Ä¶‚Ä¶‚Ä¶ üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´', 'replies': []}, {'level': 1, 'author': 'Junesathon', 'content': 'U need my flair', 'replies': []}, {'level': 1, 'author': 'n0Drip', 'content': 'üêêactivity', 'replies': []}, {'level': 1, 'author': 'CatDadd0', 'content': 'Lol I was happy with my 700 dollar gain on my monthly contracts for Nvidia, this is absolute insanity', 'replies': []}, {'level': 1, 'author': 'ProtectUrNeckWU', 'content': 'Do it again big shot', 'replies': []}, {'level': 1, 'author': 'youngkeet', 'content': 'Let me hold a dollar... jk but this is big dick shit i gotta say. Well done', 'replies': []}, {'level': 1, 'author': 'DeadByOptions', 'content': 'What was the cost of each contract?', 'replies': []}, {'level': 1, 'author': 'Dontknowgoat', 'content': 'I usually use my extra millions to get my fire started. üòÇüòÇüòÇI don‚Äôt do 1DTE. Why waste it on a gamble. Least get some heat. üòÇ', 'replies': []}, {'level': 1, 'author': 'Kenneessyy', 'content': 'Congratulations!!', 'replies': []}, {'level': 1, 'author': 'methylaminebb', 'content': 'okay this guy is starting to piss me off', 'replies': []}, {'level': 1, 'author': 'Oxy_Moronico', 'content': 'I accept tips and bribes.', 'replies': []}, {'level': 1, 'author': 'GetOffYoAssBro', 'content': 'Anyone could do that if they have your money!', 'replies': []}, {'level': 1, 'author': 'StrongDongKong', 'content': '!(emote|t5_2th52|4276)', 'replies': []}, {'level': 1, 'author': 'NigerianPrinceClub', 'content': 'wtf lol', 'replies': []}, {'level': 1, 'author': 'cryptoislife_k', 'content': 'brother what the fuck is your chatgpt 5 telling you to make such plays holy', 'replies': []}, {'level': 1, 'author': 'chadcultist', 'content': 'Welp, time for only disappointment. Good job busting your yearly nut before the end of January. !(emote|t5_2th52|12787)', 'replies': []}, {'level': 1, 'author': 'Snowballeffects', 'content': 'Wowwwwwwww', 'replies': []}, {'level': 1, 'author': 'Truman_Show_1984', 'content': \"Why don't you start posting WHEN YOU BUY and NEAR SALE TIME. I'm getting a little suspicious about all of these afters.\", 'replies': []}, {'level': 1, 'author': 'Willoni_23', 'content': 'Damn!', 'replies': []}, {'level': 1, 'author': 'EmployNeat8745', 'content': 'Holy shmoly', 'replies': []}, {'level': 1, 'author': 'NuggetBattalion', 'content': 'What the actual bleep!', 'replies': []}, {'level': 1, 'author': 'mrtomd', 'content': 'How did you decide to do these trades? What was the trigger?', 'replies': []}, {'level': 1, 'author': 'gwar11', 'content': 'Damn. I need a beer!', 'replies': []}, {'level': 1, 'author': 'd33p7r0ubl3', 'content': 'Have mods verified whether these are real posts?', 'replies': []}, {'level': 1, 'author': 'No_Art5533', 'content': 'teach me your ways üôå', 'replies': []}, {'level': 1, 'author': 'Tylord96', 'content': 'I put in a single mstr call at 300 made almost 4K on it. I wish I just yolod my account on it, but 99/100 times I‚Äôd lose that money. Hindsight is 20/20', 'replies': []}, {'level': 1, 'author': 'ManBearPig_1983', 'content': 'NVDA or bust!', 'replies': []}, {'level': 1, 'author': 'dadscallion', 'content': 'You‚Äôre either stupid or rich or both. This is how people blow accounts.', 'replies': []}, {'level': 1, 'author': 'Ashamed_Distance_144', 'content': 'You should just take the rest of the year off and chill in SPY.', 'replies': []}, {'level': 1, 'author': 'Ok_Pea_3376', 'content': 'That‚Äôs my lucky number', 'replies': []}, {'level': 1, 'author': 'Im_Fr3aKiN_0uT', 'content': \"Dog you didn't sell did you? That IV is about to shoot through the roof. If you held you'll double profits from IV alone.\", 'replies': []}, {'level': 1, 'author': 'elmajico101', 'content': 'Long time lurker. How tf do I learn this? Idk anything about trading, anywhere to start?', 'replies': []}, {'level': 1, 'author': 'BullfrogTechnical273', 'content': 'I probably sold you some of these because I‚Äôm ultra regarded !(emote|free_emotes_pack|sob)', 'replies': []}, {'level': 1, 'author': 'grabGPT', 'content': 'Your gains and nuts are alike. Uptight', 'replies': []}, {'level': 1, 'author': 'TFC_OG', 'content': 'How are the gains always happening when you post after the fact and losses happen when you call trades real time, tho?', 'replies': []}, {'level': 1, 'author': 'DOGEtothemoon21', 'content': 'How much money would you need to have to gamble in such crazy ways ? Edit: typo', 'replies': []}, {'level': 1, 'author': 'Catatafeesh1', 'content': 'This man probably just made like a trillion dollars. Fuck.', 'replies': []}, {'level': 1, 'author': 'Professor_Meteor', 'content': 'Damn! That‚Äôs dope', 'replies': []}, {'level': 1, 'author': 'joemacross', 'content': 'holy shit', 'replies': []}, {'level': 1, 'author': 'whatscookin33', 'content': 'At some point the probabilities will work against you. I‚Äôll be waiting for the $0 account post üòÇ', 'replies': []}, {'level': 1, 'author': 'xaero57', 'content': 'Jesus christ I only have 6k to invest', 'replies': []}, {'level': 1, 'author': 'StockMoeller', 'content': 'What platform are you using for a trade like this? Mine doesn‚Äôt even have 0DTE or LEAPS', 'replies': []}, {'level': 1, 'author': 'D4Junkie', 'content': 'This post told me I‚Äôm poor in 8 different ways‚Ä¶', 'replies': []}, {'level': 1, 'author': 'JustPutItInRice', 'content': 'I used to envy these posts and pray for days like this until I realized this is the equivalent to me throwing 10$ in same day options to you. OP probably is a multimillionaire people remember your own net worth folks lol', 'replies': []}]}, {'title': 'NVDA Swing Holdings üìà', 'body': 'My current NVDA holdings. What are your thoughts for next week? Sold half at $138 but now wondering how far will this ride go.', 'subreddit': 'unknown', 'comments': [{'level': 1, 'author': 'tnguyen5057', 'content': 'CES with Jensen on Monday, Cerence (CRNC) announced collaboration with NVDA today, MSFT announced investing at least 80 billion more in AI infrastructure, and PMI (economic data) beats estimates today. NVDA going up - (level 2) Comment by PlaybookTrading: Thanks for the valuable info brother üôè - (level 2) Comment by sockchaser: Nice summary!', 'replies': []}, {'level': 1, 'author': 'Zoso843', 'content': 'Any chance in hell we will be at $150 by the 10th? üëÄ - (level 2) Comment by PlaybookTrading: I wouldn‚Äôt buy an options for $150 but I do hope for that. - (level 2) Comment by Jcoronado92: I feel like shit. Sold a call for 1/10 138 strike. They will be called away next Friday. 3.2k premium for 8 contracts - (level 2) Comment by Dav1dBee: Of course no. It will get shorted soon. - (level 2) Comment by Dieseltrain760: No', 'replies': []}, {'level': 1, 'author': 'masterpiece77', 'content': 'My parents used to swing and throw swinger parties but we aren‚Äôt rich so they must not of been good at it. - (level 2) Comment by PlaybookTrading: Thought I was in the wrong reddit channel üò≥üòÇ', 'replies': []}, {'level': 1, 'author': 'Electrical_Green_258', 'content': 'Crnc sure going down on Monday.. Too much increase in a day today', 'replies': []}, {'level': 1, 'author': 'messengers1', 'content': 'My 15k won‚Äôt come until Jan. 14. Please don‚Äôt go up too high or dip lower so I can get my hand on 100 shares. - (level 2) Comment by Prince_Derrick101: Same.', 'replies': []}, {'level': 1, 'author': 'CG_throwback', 'content': 'Not swinging for less than 146-148.', 'replies': []}, {'level': 1, 'author': 'dacalo', 'content': 'Sold my leveraged positions today like LEAPS and NVDL for a nice profit. Still holding shares. If it goes up, great. If it drops, will buy more and repeat again.', 'replies': []}, {'level': 1, 'author': 'kansai828', 'content': 'Let me know when is $500', 'replies': []}, {'level': 1, 'author': 'Artistic_Original_88', 'content': \"The AI business is growing and I'm holding.\", 'replies': []}]}]}\n",
      "Analyzing posts and comments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 181.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results...\n",
      "\n",
      "Analysis complete!\n",
      "Results saved to:\n",
      "- sentiment_analysis.json (detailed analysis)\n",
      "- sentiment_summary.csv (summary statistics)\n",
      "\n",
      "Summary of analyzed posts:\n",
      "  subreddit                                            title post_sentiment  \\\n",
      "0   unknown  +$723k in NVDA 1DTE gains to start off the year       positive   \n",
      "1   unknown                            NVDA Swing Holdings üìà        neutral   \n",
      "\n",
      "   sentiment_compound  comment_count  positive_comments  neutral_comments  \\\n",
      "0                0.34             66                 23                21   \n",
      "1                0.00              9                  6                 2   \n",
      "\n",
      "   negative_comments  \n",
      "0                 22  \n",
      "1                  1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_sentiment_label(compound_score):\n",
    "    \"\"\"Convert compound score to sentiment label.\"\"\"\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "def analyze_text(text, analyzer):\n",
    "    \"\"\"Analyze sentiment of a text using VADER.\"\"\"\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    sentiment = get_sentiment_label(scores['compound'])\n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'scores': {\n",
    "            'negative': scores['neg'],\n",
    "            'neutral': scores['neu'],\n",
    "            'positive': scores['pos'],\n",
    "            'compound': scores['compound']\n",
    "        }\n",
    "    }\n",
    "\n",
    "def analyze_comments(comments, analyzer):\n",
    "    \"\"\"Analyze comments recursively.\"\"\"\n",
    "    analyzed_comments = []\n",
    "    \n",
    "    for comment in comments:\n",
    "        # Analyze current comment\n",
    "        sentiment_result = analyze_text(comment['content'], analyzer)\n",
    "        \n",
    "        analyzed_comment = {\n",
    "            'author': comment['author'],\n",
    "            'content': comment['content'],\n",
    "            'level': comment['level'],\n",
    "            'sentiment': sentiment_result['sentiment'],\n",
    "            'sentiment_scores': sentiment_result['scores']\n",
    "        }\n",
    "        \n",
    "        # Analyze replies recursively\n",
    "        if comment.get('replies'):\n",
    "            analyzed_comment['replies'] = analyze_comments(comment['replies'], analyzer)\n",
    "        else:\n",
    "            analyzed_comment['replies'] = []\n",
    "            \n",
    "        analyzed_comments.append(analyzed_comment)\n",
    "    \n",
    "    return analyzed_comments\n",
    "\n",
    "def process_data():\n",
    "    print(\"Initializing VADER sentiment analyzer...\")\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Load Reddit data\n",
    "    print(\"Loading Reddit data...\")\n",
    "    try:\n",
    "        data = get_and_parse()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Reddit data: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    analyzed_posts = []\n",
    "    \n",
    "    # Process each post\n",
    "    print(\"Analyzing posts and comments...\")\n",
    "    try:\n",
    "        for post in tqdm(data['posts'], desc=\"Processing posts\"):\n",
    "            # Analyze post content\n",
    "            post_text = f\"{post['title']} {post['body']}\"\n",
    "            post_sentiment = analyze_text(post_text, analyzer)\n",
    "            \n",
    "            analyzed_post = {\n",
    "                'subreddit': post['subreddit'],\n",
    "                'title': post['title'],\n",
    "                'body': post['body'],\n",
    "                'sentiment': post_sentiment['sentiment'],\n",
    "                'sentiment_scores': post_sentiment['scores']\n",
    "            }\n",
    "            \n",
    "            # Analyze comments if present\n",
    "            if post.get('comments'):\n",
    "                analyzed_post['comments'] = analyze_comments(post['comments'], analyzer)\n",
    "            else:\n",
    "                analyzed_post['comments'] = []\n",
    "                \n",
    "            analyzed_posts.append(analyzed_post)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Save results\n",
    "    try:\n",
    "        print(\"Saving results...\")\n",
    "        # Save detailed analysis\n",
    "        with open('sentiment_analysis.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump({'posts': analyzed_posts}, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Create summary DataFrame\n",
    "        summary_data = []\n",
    "        for post in analyzed_posts:\n",
    "            comment_sentiments = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "            \n",
    "            def count_sentiments(comments):\n",
    "                for comment in comments:\n",
    "                    comment_sentiments[comment['sentiment']] += 1\n",
    "                    if comment['replies']:\n",
    "                        count_sentiments(comment['replies'])\n",
    "            \n",
    "            count_sentiments(post['comments'])\n",
    "            \n",
    "            summary_data.append({\n",
    "                'subreddit': post['subreddit'],\n",
    "                'title': post['title'],\n",
    "                'post_sentiment': post['sentiment'],\n",
    "                'sentiment_compound': post['sentiment_scores']['compound'],\n",
    "                'comment_count': sum(comment_sentiments.values()),\n",
    "                'positive_comments': comment_sentiments['positive'],\n",
    "                'neutral_comments': comment_sentiments['neutral'],\n",
    "                'negative_comments': comment_sentiments['negative']\n",
    "            })\n",
    "        \n",
    "        # Save summary\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        df.to_csv('sentiment_summary.csv', index=False)\n",
    "        \n",
    "        print(\"\\nAnalysis complete!\")\n",
    "        print(\"Results saved to:\")\n",
    "        print(\"- sentiment_analysis.json (detailed analysis)\")\n",
    "        print(\"- sentiment_summary.csv (summary statistics)\")\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(\"\\nSummary of analyzed posts:\")\n",
    "        print(df)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing VADER sentiment analyzer...\n",
      "Loading Reddit data...\n",
      "Performing global search for 'NVDA', limit=2, sort=relevance, time_filter=day\n",
      "Fetching comments for post 1hswctz in r/wallstreetbets ...\n",
      "Fetching comments for post 1hszsor in r/NVDA_Stock ...\n",
      "{'posts': [{'title': '+$723k in NVDA 1DTE gains to start off the year', 'body': '', 'subreddit': 'unknown', 'comments': [{'level': 1, 'author': 'VisualMod', 'content': '**User Report**| | | | :--|:--|:--|:-- **Total Submissions** | 10 | **First Seen In WSB** | 4 years ago **Total Comments** | 718 | **Previous Best DD** | **Account Age** | 9 years | | [**Join WSB Discord**]', 'replies': []}, {'level': 1, 'author': 'discobr0', 'content': 'You put 133k in a 1DTE, something tells me this was peanuts to you anyway. - (level 2) Comment by Baraxton: It‚Äôs like bragging about winning at roulette. - (level 2) Comment by Cervix-Hammer: How do you even play 0dte calls? Like just by the option 1 day before expiry and hope it goes up? Does it typically have such massive gains 1dte? - (level 2) Comment by puppymaster123: And assuming he does similar amount three times a week he just recovered all his losses for the last two weeks. But those never made it to wsb tho - (level 2) Comment by Thin_Zucchini_2677: Same way you buy and sell stocks. Watch your 1m indicators and buy at low rsi macd divergence and wait - (level 2) Comment by AcanthisittaEasy5878: This 100%, or not his money - (level 2) Comment by Warchief_X: look at his post history lol. 133k is absolute absolute peanut to him - (level 2) Comment by RepresentativeWay779: If you never go Big you never win big', 'replies': []}, {'level': 1, 'author': '314159bits', 'content': \"How tf did you know it would pump like this today - (level 2) Comment by PercyPeru: He didn‚Äôt. Thats the magic - (level 2) Comment by Nanas_700k: He might not have expected such a move, but once he was on the right side of the trade he let his winners run as many good traders knows to do - (level 2) Comment by moistpimplee: he gambled. hes also rich as fuck. so it doesn't matter - (level 2) Comment by MostRadiant: I am guessing he believed stocks not influenced by China recession would recover quickly. - (level 2) Comment by fliesenschieber: He's an expert - (level 2) Comment by reddit-abcde: He is an insider\", 'replies': []}, {'level': 1, 'author': 'J82nd', 'content': 'I sold 1 covered call 0dte 145 made $27.34 after fee. Not sure how everyone is buying over 100 calls unless you have a multi million dollar account. - (level 2) Comment by collegegirlsgw: Bingo lol that‚Äôs exactly what this guy has - (level 2) Comment by DrunkRespondent: Easy, just buy naked.', 'replies': []}, {'level': 1, 'author': 'NYGBobby', 'content': 'Rich guy gets richer cool - (level 2) Comment by whatisthereallife: \"Just git gud scrub\" - rich people - (level 2) Comment by main135: that\\'s how it works - (level 2) Comment by fuzzywuzzy123: I love happy endings!', 'replies': []}, {'level': 1, 'author': 'Evander85', 'content': \"I would have sold this position when it was up 5% which is why I‚Äôm a Brokie - (level 2) Comment by Ok_Battle_4082: Reminder that you don‚Äôt see the other x amount of trades that this guy probably lost the same amount or more on - (level 2) Comment by e2can: A wins a win - (level 2) Comment by Mycatspiss: OP a trust fund kid which is why he didn't sell. Don't beat yourself up\", 'replies': []}, {'level': 1, 'author': 'Kekulzor', 'content': 'Dad, I finally found you after all these years - (level 2) Comment by wedditmod: Brother?', 'replies': []}, {'level': 1, 'author': 'buddumz', 'content': 'https://preview.redd.it/dlw46c1revae1.jpeg?width=654&amp;format=pjpg&amp;auto=webp&amp;s=b254e851e7531199ade8e1bc37764519fe30aa80 I was in this too üòé', 'replies': []}, {'level': 1, 'author': 'A_and_P_Armory', 'content': 'The 320 calls today had a 100x low to high (0.20 to 20.00). That‚Äôs crazy. Real world potential gain there. I‚Äôm up 5200% in an option now (over several months of holding), but 10,000% range in a day is crazy nice. Congrats for putting your nuts out there. - (level 2) Comment by crankthehandle: yeah, 5200% sucks big times - (level 2) Comment by mikeysd123: To be fair theres 100x plays almost every day on 0DTEs - (level 2) Comment by Ill_Cancel4937: Lol what option and stock do you have that much faith in to hold a 52 bagger?', 'replies': []}, {'level': 1, 'author': 'convexdominance6', 'content': \"Bought yesterday and sold throughout the day today. MSTR post to follow next week :) - (level 2) Comment by soploping: How long did it take u to acquire this amount of wealth - (level 2) Comment by youngkeet: Oh i am excited for this. I went full port and lost my ass tbh......sold at 419 after buying $460ish and then again at 490 Thats the difference between me and you. Im ACTUALLY regarded - (level 2) Comment by NyCWalker76: Which broker is this? - (level 2) Comment by TarzanSwingTrades: MSTR calls or puts? - (level 2) Comment by HappyCurrencies: what's the most you've lost in a trade?\", 'replies': []}, {'level': 1, 'author': '2toneSound', 'content': 'Teach me master üôè', 'replies': []}, {'level': 1, 'author': 'LowCryptographer9047', 'content': 'I remember this guy ‚Äúthe son of jack dorsey‚Äù not his first big win', 'replies': []}, {'level': 1, 'author': 'danlyh', 'content': 'putting over 100k into 1DTE options huh https://preview.redd.it/doxilsbmuuae1.jpeg?width=1179&amp;format=pjpg&amp;auto=webp&amp;s=c83dca1e7d268a35dbf904f4bc5dc226e4fdc4a0 - (level 2) Comment by IVcrushonYou: Beat me to it. ü§£', 'replies': []}, {'level': 1, 'author': 'lovesToClap', 'content': 'guy has insane gains in his post history...wtf - (level 2) Comment by LoDyes: 1.2 mil in a day..', 'replies': []}, {'level': 1, 'author': 'bluecgene', 'content': 'This is Warren Buffett on his play account‚Ä¶ enjoying the last moments', 'replies': []}, {'level': 1, 'author': 'Glittering_Poetry_60', 'content': 'You have 2k of my money. Congrats you glorious bastard', 'replies': []}, {'level': 1, 'author': 'DeepestWinterBlue', 'content': 'Disgustingly bold move', 'replies': []}, {'level': 1, 'author': 'DepartmentBig2849', 'content': 'üê≥', 'replies': []}, {'level': 1, 'author': 'ericz0r', 'content': 'Now share the rest of your weekly options plays for the last week too. - (level 2) Comment by rain168: Didn‚Äôt he also buy 1.3M calls on SPXW that expired worthless today? He‚Äôs obviously rich, so all these are just play money.', 'replies': []}, {'level': 1, 'author': 'Intelligent_Flan_571', 'content': 'This bro is always pulling off these 1-3DTE plays ‚Ä¶is he the chosen one or is he hiding his 7 digit losses from us ü§®', 'replies': []}, {'level': 1, 'author': 'miktoo', 'content': 'what a way to start the year', 'replies': []}, {'level': 1, 'author': 'missmypinto', 'content': 'Should‚Äôve bought TSLA 0dTE you‚Äôd have made about 3.5 mil', 'replies': []}, {'level': 1, 'author': 'urpapi_1', 'content': 'What the flying fu‚Ä¶‚Ä¶‚Ä¶ üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´üòµ\\u200düí´', 'replies': []}, {'level': 1, 'author': 'Junesathon', 'content': 'U need my flair', 'replies': []}, {'level': 1, 'author': 'n0Drip', 'content': 'üêêactivity', 'replies': []}, {'level': 1, 'author': 'CatDadd0', 'content': 'Lol I was happy with my 700 dollar gain on my monthly contracts for Nvidia, this is absolute insanity', 'replies': []}, {'level': 1, 'author': 'ProtectUrNeckWU', 'content': 'Do it again big shot', 'replies': []}, {'level': 1, 'author': 'youngkeet', 'content': 'Let me hold a dollar... jk but this is big dick shit i gotta say. Well done', 'replies': []}, {'level': 1, 'author': 'DeadByOptions', 'content': 'What was the cost of each contract?', 'replies': []}, {'level': 1, 'author': 'Dontknowgoat', 'content': 'I usually use my extra millions to get my fire started. üòÇüòÇüòÇI don‚Äôt do 1DTE. Why waste it on a gamble. Least get some heat. üòÇ', 'replies': []}, {'level': 1, 'author': 'Kenneessyy', 'content': 'Congratulations!!', 'replies': []}, {'level': 1, 'author': 'methylaminebb', 'content': 'okay this guy is starting to piss me off', 'replies': []}, {'level': 1, 'author': 'Oxy_Moronico', 'content': 'I accept tips and bribes.', 'replies': []}, {'level': 1, 'author': 'GetOffYoAssBro', 'content': 'Anyone could do that if they have your money!', 'replies': []}, {'level': 1, 'author': 'StrongDongKong', 'content': '!(emote|t5_2th52|4276)', 'replies': []}, {'level': 1, 'author': 'NigerianPrinceClub', 'content': 'wtf lol', 'replies': []}, {'level': 1, 'author': 'cryptoislife_k', 'content': 'brother what the fuck is your chatgpt 5 telling you to make such plays holy', 'replies': []}, {'level': 1, 'author': 'chadcultist', 'content': 'Welp, time for only disappointment. Good job busting your yearly nut before the end of January. !(emote|t5_2th52|12787)', 'replies': []}, {'level': 1, 'author': 'Snowballeffects', 'content': 'Wowwwwwwww', 'replies': []}, {'level': 1, 'author': 'Truman_Show_1984', 'content': \"Why don't you start posting WHEN YOU BUY and NEAR SALE TIME. I'm getting a little suspicious about all of these afters.\", 'replies': []}, {'level': 1, 'author': 'Willoni_23', 'content': 'Damn!', 'replies': []}, {'level': 1, 'author': 'EmployNeat8745', 'content': 'Holy shmoly', 'replies': []}, {'level': 1, 'author': 'NuggetBattalion', 'content': 'What the actual bleep!', 'replies': []}, {'level': 1, 'author': 'mrtomd', 'content': 'How did you decide to do these trades? What was the trigger?', 'replies': []}, {'level': 1, 'author': 'gwar11', 'content': 'Damn. I need a beer!', 'replies': []}, {'level': 1, 'author': 'd33p7r0ubl3', 'content': 'Have mods verified whether these are real posts?', 'replies': []}, {'level': 1, 'author': 'No_Art5533', 'content': 'teach me your ways üôå', 'replies': []}, {'level': 1, 'author': 'Tylord96', 'content': 'I put in a single mstr call at 300 made almost 4K on it. I wish I just yolod my account on it, but 99/100 times I‚Äôd lose that money. Hindsight is 20/20', 'replies': []}, {'level': 1, 'author': 'ManBearPig_1983', 'content': 'NVDA or bust!', 'replies': []}, {'level': 1, 'author': 'dadscallion', 'content': 'You‚Äôre either stupid or rich or both. This is how people blow accounts.', 'replies': []}, {'level': 1, 'author': 'Ashamed_Distance_144', 'content': 'You should just take the rest of the year off and chill in SPY.', 'replies': []}, {'level': 1, 'author': 'Ok_Pea_3376', 'content': 'That‚Äôs my lucky number', 'replies': []}, {'level': 1, 'author': 'Im_Fr3aKiN_0uT', 'content': \"Dog you didn't sell did you? That IV is about to shoot through the roof. If you held you'll double profits from IV alone.\", 'replies': []}, {'level': 1, 'author': 'elmajico101', 'content': 'Long time lurker. How tf do I learn this? Idk anything about trading, anywhere to start?', 'replies': []}, {'level': 1, 'author': 'BullfrogTechnical273', 'content': 'I probably sold you some of these because I‚Äôm ultra regarded !(emote|free_emotes_pack|sob)', 'replies': []}, {'level': 1, 'author': 'grabGPT', 'content': 'Your gains and nuts are alike. Uptight', 'replies': []}, {'level': 1, 'author': 'TFC_OG', 'content': 'How are the gains always happening when you post after the fact and losses happen when you call trades real time, tho?', 'replies': []}, {'level': 1, 'author': 'DOGEtothemoon21', 'content': 'How much money would you need to have to gamble in such crazy ways ? Edit: typo', 'replies': []}, {'level': 1, 'author': 'Catatafeesh1', 'content': 'This man probably just made like a trillion dollars. Fuck.', 'replies': []}, {'level': 1, 'author': 'Professor_Meteor', 'content': 'Damn! That‚Äôs dope', 'replies': []}, {'level': 1, 'author': 'joemacross', 'content': 'holy shit', 'replies': []}, {'level': 1, 'author': 'whatscookin33', 'content': 'At some point the probabilities will work against you. I‚Äôll be waiting for the $0 account post üòÇ', 'replies': []}, {'level': 1, 'author': 'xaero57', 'content': 'Jesus christ I only have 6k to invest', 'replies': []}, {'level': 1, 'author': 'StockMoeller', 'content': 'What platform are you using for a trade like this? Mine doesn‚Äôt even have 0DTE or LEAPS', 'replies': []}, {'level': 1, 'author': 'D4Junkie', 'content': 'This post told me I‚Äôm poor in 8 different ways‚Ä¶', 'replies': []}, {'level': 1, 'author': 'JustPutItInRice', 'content': 'I used to envy these posts and pray for days like this until I realized this is the equivalent to me throwing 10$ in same day options to you. OP probably is a multimillionaire people remember your own net worth folks lol', 'replies': []}]}, {'title': 'NVDA Swing Holdings üìà', 'body': 'My current NVDA holdings. What are your thoughts for next week? Sold half at $138 but now wondering how far will this ride go.', 'subreddit': 'unknown', 'comments': [{'level': 1, 'author': 'tnguyen5057', 'content': 'CES with Jensen on Monday, Cerence (CRNC) announced collaboration with NVDA today, MSFT announced investing at least 80 billion more in AI infrastructure, and PMI (economic data) beats estimates today. NVDA going up - (level 2) Comment by PlaybookTrading: Thanks for the valuable info brother üôè - (level 2) Comment by sockchaser: Nice summary!', 'replies': []}, {'level': 1, 'author': 'Zoso843', 'content': 'Any chance in hell we will be at $150 by the 10th? üëÄ - (level 2) Comment by PlaybookTrading: I wouldn‚Äôt buy an options for $150 but I do hope for that. - (level 2) Comment by Jcoronado92: I feel like shit. Sold a call for 1/10 138 strike. They will be called away next Friday. 3.2k premium for 8 contracts - (level 2) Comment by Dav1dBee: Of course no. It will get shorted soon. - (level 2) Comment by Dieseltrain760: No', 'replies': []}, {'level': 1, 'author': 'masterpiece77', 'content': 'My parents used to swing and throw swinger parties but we aren‚Äôt rich so they must not of been good at it. - (level 2) Comment by PlaybookTrading: Thought I was in the wrong reddit channel üò≥üòÇ', 'replies': []}, {'level': 1, 'author': 'Electrical_Green_258', 'content': 'Crnc sure going down on Monday.. Too much increase in a day today', 'replies': []}, {'level': 1, 'author': 'messengers1', 'content': 'My 15k won‚Äôt come until Jan. 14. Please don‚Äôt go up too high or dip lower so I can get my hand on 100 shares. - (level 2) Comment by Prince_Derrick101: Same.', 'replies': []}, {'level': 1, 'author': 'CG_throwback', 'content': 'Not swinging for less than 146-148.', 'replies': []}, {'level': 1, 'author': 'dacalo', 'content': 'Sold my leveraged positions today like LEAPS and NVDL for a nice profit. Still holding shares. If it goes up, great. If it drops, will buy more and repeat again.', 'replies': []}, {'level': 1, 'author': 'kansai828', 'content': 'Let me know when is $500', 'replies': []}, {'level': 1, 'author': 'Artistic_Original_88', 'content': \"The AI business is growing and I'm holding.\", 'replies': []}]}]}\n",
      "Analyzing posts and comments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 69.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results...\n",
      "\n",
      "Analysis complete!\n",
      "Results saved to:\n",
      "- sentiment_analysis.json (detailed analysis)\n",
      "- sentiment_summary.csv (summary statistics)\n",
      "\n",
      "Summary of analyzed posts:\n",
      "  subreddit                                            title post_sentiment  \\\n",
      "0   unknown  +$723k in NVDA 1DTE gains to start off the year       positive   \n",
      "1   unknown                            NVDA Swing Holdings üìà        neutral   \n",
      "\n",
      "   sentiment_compound  comment_count  positive_comments  neutral_comments  \\\n",
      "0                0.34             66                 23                21   \n",
      "1                0.00              9                  6                 2   \n",
      "\n",
      "   negative_comments  \n",
      "0                 22  \n",
      "1                  1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_posts': 2, 'sentiment_distribution': {'positive': 1, 'neutral': 1}, 'comment_statistics': {'total_comments': 75, 'positive_comments': 29, 'neutral_comments': 23, 'negative_comments': 23}, 'subreddits': ['unknown'], 'average_compound_score': 0.17}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\"Custom encoder for numpy data types\"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "                          np.int16, np.int32, np.int64, np.uint8,\n",
    "                          np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "class SentimentVisualizer:\n",
    "    def __init__(self, df):\n",
    "        \"\"\"Initialize with path to sentiment analysis CSV file.\"\"\"\n",
    "        self.df = df\n",
    "        \n",
    "        # Set style\n",
    "        plt.style.use('seaborn-v0_8')\n",
    "        sns.set_palette(\"husl\")\n",
    "        \n",
    "    def create_sentiment_distribution(self, save_path='figures'):\n",
    "        \"\"\"Create sentiment distribution plots.\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Posts sentiment distribution\n",
    "        posts_sentiment_counts = self.df['post_sentiment'].value_counts()\n",
    "        sns.barplot(x=posts_sentiment_counts.index, y=posts_sentiment_counts.values, ax=ax1)\n",
    "        ax1.set_title('Post Sentiment Distribution')\n",
    "        ax1.set_ylabel('Count')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Comments distribution (positive/neutral/negative)\n",
    "        comment_counts = pd.DataFrame({\n",
    "            'Sentiment': ['Positive', 'Neutral', 'Negative'],\n",
    "            'Count': [\n",
    "                self.df['positive_comments'].sum(),\n",
    "                self.df['neutral_comments'].sum(),\n",
    "                self.df['negative_comments'].sum()\n",
    "            ]\n",
    "        })\n",
    "        sns.barplot(data=comment_counts, x='Sentiment', y='Count', ax=ax2)\n",
    "        ax2.set_title('Comment Sentiment Distribution')\n",
    "        ax2.set_ylabel('Count')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.figure(figsize=(15, 6))  # Create new figure with larger size\n",
    "        plt.subplots_adjust(bottom=0.2)  # Adjust bottom margin\n",
    "        # plt.savefig(f'{save_path}/sentiment_distribution.png', bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "    def create_compound_score_plot(self, save_path='figures'):\n",
    "        \"\"\"Create compound score visualization.\"\"\"\n",
    "        plt.figure(figsize=(15, 8))  # Increased figure size\n",
    "        \n",
    "        # Create bar plot of compound scores\n",
    "        bars = plt.bar(range(len(self.df)), self.df['sentiment_compound'])\n",
    "        \n",
    "        # Color bars based on sentiment\n",
    "        colors = {'positive': 'green', 'neutral': 'gray', 'negative': 'red'}\n",
    "        for bar, sentiment in zip(bars, self.df['post_sentiment']):\n",
    "            bar.set_color(colors[sentiment])\n",
    "        \n",
    "        plt.title('Sentiment Compound Scores by Post', pad=20)\n",
    "        plt.xlabel('Posts')\n",
    "        plt.ylabel('Compound Score')\n",
    "        \n",
    "        # Rotate and align the tick labels so they look better\n",
    "        plt.xticks(range(len(self.df)), \n",
    "                  self.df['title'].str[:30] + '...', \n",
    "                  rotation=45,\n",
    "                  ha='right')\n",
    "        \n",
    "        # Add horizontal line at y=0\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.2)\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.subplots_adjust(bottom=0.2)\n",
    "        \n",
    "        # plt.savefig(f'{save_path}/compound_scores.png', bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "    def create_subreddit_analysis(self, save_path='figures'):\n",
    "        \"\"\"Create subreddit-level sentiment analysis.\"\"\"\n",
    "        if self.df['subreddit'].nunique() > 1:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            subreddit_sentiment = pd.crosstab(self.df['subreddit'], self.df['post_sentiment'])\n",
    "            subreddit_sentiment.plot(kind='bar', stacked=True)\n",
    "            \n",
    "            plt.title('Sentiment Distribution by Subreddit')\n",
    "            plt.xlabel('Subreddit')\n",
    "            plt.ylabel('Count')\n",
    "            plt.legend(title='Sentiment')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            \n",
    "            plt.subplots_adjust(bottom=0.2)\n",
    "            # plt.savefig(f'{save_path}/subreddit_sentiment.png', bbox_inches='tight', dpi=300)\n",
    "            plt.close()\n",
    "    \n",
    "    def create_comment_analysis(self, save_path='figures'):\n",
    "        \"\"\"Create visualization of comments analysis.\"\"\"\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Prepare data\n",
    "        comments_data = self.df[['title', 'positive_comments', 'neutral_comments', 'negative_comments']]\n",
    "        comments_data = comments_data.set_index('title')\n",
    "        \n",
    "        # Create stacked bar chart\n",
    "        ax = comments_data.plot(kind='bar', stacked=True)\n",
    "        \n",
    "        plt.title('Comment Sentiment Distribution by Post')\n",
    "        plt.xlabel('Posts')\n",
    "        plt.ylabel('Number of Comments')\n",
    "        plt.legend(title='Comment Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # Rotate and align the tick labels so they look better\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Adjust layout to prevent label cutoff\n",
    "        plt.subplots_adjust(bottom=0.2, right=0.85)\n",
    "        # plt.savefig(f'{save_path}/comments_analysis.png', bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "    def create_all_visualizations(self, save_path='figures'):\n",
    "        \"\"\"Create all visualizations.\"\"\"\n",
    "        # Create output directory if it doesn't exist\n",
    "        # Path(save_path).mkdir(exist_ok=True)\n",
    "        \n",
    "        self.create_sentiment_distribution(save_path)\n",
    "        self.create_compound_score_plot(save_path)\n",
    "        self.create_subreddit_analysis(save_path)\n",
    "        self.create_comment_analysis(save_path)\n",
    "        \n",
    "        # Create summary statistics with native Python types\n",
    "        summary = {\n",
    "            'total_posts': int(len(self.df)),\n",
    "            'sentiment_distribution': {\n",
    "                k: int(v) for k, v in self.df['post_sentiment'].value_counts().to_dict().items()\n",
    "            },\n",
    "            'comment_statistics': {\n",
    "                'total_comments': int(self.df['comment_count'].sum()),\n",
    "                'positive_comments': int(self.df['positive_comments'].sum()),\n",
    "                'neutral_comments': int(self.df['neutral_comments'].sum()),\n",
    "                'negative_comments': int(self.df['negative_comments'].sum())\n",
    "            },\n",
    "            'subreddits': self.df['subreddit'].unique().tolist(),\n",
    "            'average_compound_score': float(self.df['sentiment_compound'].mean())\n",
    "        }\n",
    "        \n",
    "        # Save summary to JSON using custom encoder\n",
    "        # with open(f'{save_path}/analysis_summary.json', 'w', encoding='utf-8') as f:\n",
    "        #     json.dump(summary, f, indent=2, cls=NumpyEncoder)\n",
    "        \n",
    "        return summary\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize visualizer\n",
    "        visualizer = SentimentVisualizer(\n",
    "            df=process_data()\n",
    "        )\n",
    "        \n",
    "        # Create all visualizations\n",
    "        result = visualizer.create_all_visualizations()\n",
    "        \n",
    "        # print(\"Visualizations have been created in the 'figures' directory!\")\n",
    "        # print(\"The following files were generated:\")\n",
    "        # print(\"- sentiment_distribution.png\")\n",
    "        # print(\"- compound_scores.png\")\n",
    "        # print(\"- subreddit_sentiment.png\")\n",
    "        # print(\"- comments_analysis.png\")\n",
    "        # print(\"- analysis_summary.json\")\n",
    "        print(result)   \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
